{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>#–ò–¥–µ—è üß† –ó–∞–∫—Ä—ã—Ç—ã–µ –∏–¥–µ–∏ –ú–æ–∑–≥–æ–≤–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∞ –°–∏–≥–Ω–∞–ª–æ...</td>\n",
       "      <td>225-3;127-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>#–†–∞—Å–ø–∞–¥—Å–∫–∞—è. –û–±–∑–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ –†...</td>\n",
       "      <td>129-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7154</th>\n",
       "      <td>ü§∑‚Äç‚ôÇ¬´–ì–∞–∑–ø—Ä–æ–º¬ª —Ö–æ—á–µ—Ç –ø–æ–ø—Ä–∞–≤–∏—Ç—å —Å–≤–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –∑–∞...</td>\n",
       "      <td>48-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>üõ¢ –õ—É–∫–æ–π–ª - –¥–µ–Ω—å–≥–∏ –µ—Å—Ç—å!  –û—Ç—á–µ—Ç –∑–∞ 1 –ø–æ–ª—É–≥–æ–¥–∏–µ ...</td>\n",
       "      <td>111-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>–†—ã–Ω–∫–∏ —É—Ç—Ä–æ–º  üî∏–î–µ–ª–æ –æ –±–∞–Ω–∫—Ä–æ—Ç—Å—Ç–≤–µ –°–ü–ë –ë–∏—Ä–∂–∏ –ø–æ—è...</td>\n",
       "      <td>230-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>üìâ –ü–æ–∫–∞—Ç–∏–ª–∏—Å—å –≤–Ω–∏–∑: –¥–æ –∫–∞–∫–∏—Ö —É—Ä–æ–≤–Ω–µ–π –º–æ–≥—É—Ç —É–ø–∞—Å...</td>\n",
       "      <td>152-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>üèÅ –ò—Ç–æ–≥–∏ –¥–Ω—è: 13 –º–∞—Ä—Ç–∞    üî∏ –ü—Ä–æ–¥–∞–∂–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ...</td>\n",
       "      <td>4-5;241-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>–†—ã–Ω–∫–∏ —É—Ç—Ä–æ–º  üî∏ –°–ü–ë –±–∏—Ä–∂–∞ —Ö–æ—á–µ—Ç –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≥–æ–Ω–∫–æ...</td>\n",
       "      <td>225-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>#–¢–µ—Ö–∞–Ω–∞–ª–∏–∑  üí° –¢–µ–∫—É—â–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–¥–µ–ª–∞ –¢–µ—Ö–∞–Ω–∞–ª–∏...</td>\n",
       "      <td>127-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>üîº –¢–æ—Ä–≥–∏ –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ –Ω–∞—á–∞–ª–∏—Å—å –≤ –ø–ª—é—Å–µ: ...</td>\n",
       "      <td>221-3;111-3;112-3;163-3;236-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6992</th>\n",
       "      <td>üü¢ –ù–æ–≤–æ—Å—Ç–∏ –∫ —ç—Ç–æ–º—É —á–∞—Å—É  ‚ö™Ô∏è –•–æ–ª–¥–∏–Ω–≥–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏...</td>\n",
       "      <td>103-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>üîç –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: VK —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ IV –∫–≤. ...</td>\n",
       "      <td>223-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#–ª–µ—Å #—Ä–æ—Å—Å–∏—è #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –í —è–Ω–≤–∞—Ä–µ –∏ —Ñ–µ–≤—Ä–∞...</td>\n",
       "      <td>204-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>–†–µ–π—Ç–∏–Ω–≥ –∞–∫—Ü–∏–π –ø–æ —á–∏—Å—Ç—ã–º –ø–æ–∫—É–ø–∫–∞–º –∏ —á–∏—Å—Ç—ã–º –ø—Ä–æ–¥...</td>\n",
       "      <td>231-4;152-3;227-3;219-3;74-3;129-3;11-3;160-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>\"–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å \"\"–†–æ—Å–Ω–µ—Ñ—Ç–∏\"\" –ø–æ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º ...</td>\n",
       "      <td>112-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#MAGN #–¥–∏–≤–∏–¥–µ–Ω–¥  –∞–∫—Ü–∏–æ–Ω–µ—Ä—ã –ú–ú–ö: –¥–∏–≤–∏–¥–µ–Ω–¥—ã ...</td>\n",
       "      <td>90-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>üõí –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú.–í–∏–¥–µ–æ¬ª —Ä–∞—Å–∫—Ä—ã–ª–∞ –≤–æ—Å—Å—Ç...</td>\n",
       "      <td>88-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>–° 9 –º–∞—Ä—Ç–∞ –ú–æ—Å–±–∏—Ä–∂–∞ —É–≤–µ–ª–∏—á–∏—Ç —á–∏—Å–ª–æ –±—É–º–∞–≥, —Ç–æ—Ä–≥—É...</td>\n",
       "      <td>103-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>üí•üá∑üá∫#TRMK = +7%</td>\n",
       "      <td>177-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>\"–û–∂–∏–¥–∞–µ–º–∞—è –¥–∏–≤–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø–æ –ø—Ä–µ—Ñ–∞–º ¬´–ë–∞—à–Ω–µ—Ñ—Ç–∏¬ª ...</td>\n",
       "      <td>160-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "1746  #–ò–¥–µ—è üß† –ó–∞–∫—Ä—ã—Ç—ã–µ –∏–¥–µ–∏ –ú–æ–∑–≥–æ–≤–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∞ –°–∏–≥–Ω–∞–ª–æ...   \n",
       "1772  #–†–∞—Å–ø–∞–¥—Å–∫–∞—è. –û–±–∑–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –ø–æ –†...   \n",
       "7154  ü§∑‚Äç‚ôÇ¬´–ì–∞–∑–ø—Ä–æ–º¬ª —Ö–æ—á–µ—Ç –ø–æ–ø—Ä–∞–≤–∏—Ç—å —Å–≤–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –∑–∞...   \n",
       "6746  üõ¢ –õ—É–∫–æ–π–ª - –¥–µ–Ω—å–≥–∏ –µ—Å—Ç—å!  –û—Ç—á–µ—Ç –∑–∞ 1 –ø–æ–ª—É–≥–æ–¥–∏–µ ...   \n",
       "3106  –†—ã–Ω–∫–∏ —É—Ç—Ä–æ–º  üî∏–î–µ–ª–æ –æ –±–∞–Ω–∫—Ä–æ—Ç—Å—Ç–≤–µ –°–ü–ë –ë–∏—Ä–∂–∏ –ø–æ—è...   \n",
       "6309  üìâ –ü–æ–∫–∞—Ç–∏–ª–∏—Å—å –≤–Ω–∏–∑: –¥–æ –∫–∞–∫–∏—Ö —É—Ä–æ–≤–Ω–µ–π –º–æ–≥—É—Ç —É–ø–∞—Å...   \n",
       "5565  üèÅ –ò—Ç–æ–≥–∏ –¥–Ω—è: 13 –º–∞—Ä—Ç–∞    üî∏ –ü—Ä–æ–¥–∞–∂–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ...   \n",
       "3105  –†—ã–Ω–∫–∏ —É—Ç—Ä–æ–º  üî∏ –°–ü–ë –±–∏—Ä–∂–∞ —Ö–æ—á–µ—Ç –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≥–æ–Ω–∫–æ...   \n",
       "1775  #–¢–µ—Ö–∞–Ω–∞–ª–∏–∑  üí° –¢–µ–∫—É—â–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–¥–µ–ª–∞ –¢–µ—Ö–∞–Ω–∞–ª–∏...   \n",
       "6605  üîº –¢–æ—Ä–≥–∏ –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ –Ω–∞—á–∞–ª–∏—Å—å –≤ –ø–ª—é—Å–µ: ...   \n",
       "6992  üü¢ –ù–æ–≤–æ—Å—Ç–∏ –∫ —ç—Ç–æ–º—É —á–∞—Å—É  ‚ö™Ô∏è –•–æ–ª–¥–∏–Ω–≥–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏...   \n",
       "6502  üîç –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: VK —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ IV –∫–≤. ...   \n",
       "4273  ‚ö†Ô∏èüá∑üá∫#–ª–µ—Å #—Ä–æ—Å—Å–∏—è #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –í —è–Ω–≤–∞—Ä–µ –∏ —Ñ–µ–≤—Ä–∞...   \n",
       "3044  –†–µ–π—Ç–∏–Ω–≥ –∞–∫—Ü–∏–π –ø–æ —á–∏—Å—Ç—ã–º –ø–æ–∫—É–ø–∫–∞–º –∏ —á–∏—Å—Ç—ã–º –ø—Ä–æ–¥...   \n",
       "365   \"–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å \"\"–†–æ—Å–Ω–µ—Ñ—Ç–∏\"\" –ø–æ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º ...   \n",
       "4210  ‚ö†Ô∏èüá∑üá∫#MAGN #–¥–∏–≤–∏–¥–µ–Ω–¥  –∞–∫—Ü–∏–æ–Ω–µ—Ä—ã –ú–ú–ö: –¥–∏–≤–∏–¥–µ–Ω–¥—ã ...   \n",
       "6730  üõí –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú.–í–∏–¥–µ–æ¬ª —Ä–∞—Å–∫—Ä—ã–ª–∞ –≤–æ—Å—Å—Ç...   \n",
       "3119  –° 9 –º–∞—Ä—Ç–∞ –ú–æ—Å–±–∏—Ä–∂–∞ —É–≤–µ–ª–∏—á–∏—Ç —á–∏—Å–ª–æ –±—É–º–∞–≥, —Ç–æ—Ä–≥—É...   \n",
       "6084                                     üí•üá∑üá∫#TRMK = +7%   \n",
       "254   \"–û–∂–∏–¥–∞–µ–º–∞—è –¥–∏–≤–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø–æ –ø—Ä–µ—Ñ–∞–º ¬´–ë–∞—à–Ω–µ—Ñ—Ç–∏¬ª ...   \n",
       "\n",
       "                                        target_text  prefix  \n",
       "1746                                    225-3;127-3  clsorg  \n",
       "1772                                          129-3  clsorg  \n",
       "7154                                           48-3  clsorg  \n",
       "6746                                          111-4  clsorg  \n",
       "3106                                          230-4  clsorg  \n",
       "6309                                          152-3  clsorg  \n",
       "5565                                      4-5;241-4  clsorg  \n",
       "3105                                          225-4  clsorg  \n",
       "1775                                          127-4  clsorg  \n",
       "6605                  221-3;111-3;112-3;163-3;236-3  clsorg  \n",
       "6992                                          103-4  clsorg  \n",
       "6502                                          223-4  clsorg  \n",
       "4273                                          204-2  clsorg  \n",
       "3044  231-4;152-3;227-3;219-3;74-3;129-3;11-3;160-4  clsorg  \n",
       "365                                           112-4  clsorg  \n",
       "4210                                           90-2  clsorg  \n",
       "6730                                           88-4  clsorg  \n",
       "3119                                          103-4  clsorg  \n",
       "6084                                          177-3  clsorg  \n",
       "254                                           160-4  clsorg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [pin]\n",
    "file_path = \"../data/data-hard.csv\"\n",
    "root_path = \"../data/\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"prefix\"] = \"clsorg\"\n",
    "df = df.rename({\"message\": \"input_text\", \"label\": \"target_text\"}, axis=1)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "m_name = \"cointegrated/rut5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.t5.dataset import NERDataModel\n",
    "from src.t5.model import NERModel\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "data_module = NERDataModel(train_df, test_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 8 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=8)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = NERModel()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"ner\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'lightning_logs': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/jovyan/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/lightning_logs\n",
      "/home/jovyan/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/jovyan/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/jovyan/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69307d9a5c044a408a83de2c06fea154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 85: 'val_loss' reached 1.92267 (best 1.92267), saving model to '/home/jovyan/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 170: 'val_loss' reached 1.29129 (best 1.29129), saving model to '/home/jovyan/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 255: 'val_loss' reached 1.19559 (best 1.19559), saving model to '/home/jovyan/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 340: 'val_loss' reached 1.11470 (best 1.11470), saving model to '/home/jovyan/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 425: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 510: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 595: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 680: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 765: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 850: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_model = NERModel.load_from_checkpoint(\"checkpoints/ner-v2.ckpt\")\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, SequentialSampler, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5Tokenizer\n",
    "import time\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        input_text = item[\"prefix\"] + \": \" + item[\"input_text\"]\n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        encoding[\"input_ids\"] = encoding[\"input_ids\"].squeeze(0)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "def generate_answer_batched_v2(\n",
    "    trained_model: NERModel,\n",
    "    tokenizer: T5Tokenizer,\n",
    "    data: pd.DataFrame,\n",
    "    batch_size: int = 64,\n",
    "    dataloader_workers: int = 16\n",
    "):\n",
    "    predictions = []\n",
    "    dataset = CustomDataset(data, tokenizer, max_length=396)\n",
    "    sequential_sampler = SequentialSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sequential_sampler, num_workers=dataloader_workers)\n",
    "    with torch.no_grad():\n",
    "        for source_encoding in tqdm(dataloader):\n",
    "            t0 = time.time()\n",
    "            generated_ids = trained_model.model.generate(\n",
    "                input_ids=source_encoding[\"input_ids\"].cuda(),\n",
    "                attention_mask=source_encoding[\"attention_mask\"].cuda(),\n",
    "                num_beams=3,\n",
    "                max_length=80,\n",
    "                temperature=0.5,\n",
    "                repetition_penalty=1.0,\n",
    "                early_stopping=True,\n",
    "                use_cache=True,\n",
    "            ).cpu()\n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            predictions.append(preds)\n",
    "\n",
    "    return sum(predictions, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.t5.utils import evaluate_metric, generate_answer_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd9c8683f0a4cb49ca2ade8af4cc8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.3 s, sys: 178 ms, total: 21.5 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = generate_answer_batched(\n",
    "    trained_model=trained_model, tokenizer=tokenizer, data=test_df, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110ea583ded6403f8f9647b5dedf0015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.2 s, sys: 656 ms, total: 20.8 s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = generate_answer_batched_v2(\n",
    "    trained_model=trained_model, tokenizer=tokenizer, data=test_df, batch_size=64, dataloader_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = test_df.copy()\n",
    "ldf[\"predictions\"] = predictions\n",
    "ldf[[\"tcomp\", \"tsent\"]] = (\n",
    "    ldf[\"target_text\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")\n",
    "ldf[[\"pcomp\", \"psent\"]] = (\n",
    "    ldf[\"predictions\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'av'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# [pin]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompany_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mldf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpcomp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompany_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mldf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtcomp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentiment_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mldf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpsent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentiment_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mldf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtsent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/../src/t5/utils.py:124\u001b[0m, in \u001b[0;36mevaluate_metric\u001b[0;34m(company_labels, company_predictions, sentiment_labels, sentiment_predictions)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_metric\u001b[39m(\n\u001b[1;32m    122\u001b[0m     company_labels, company_predictions, sentiment_labels, sentiment_predictions\n\u001b[1;32m    123\u001b[0m ):\n\u001b[0;32m--> 124\u001b[0m     f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_f1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompany_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompany_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     acc_score \u001b[38;5;241m=\u001b[39m evaluate_accuracy(sentiment_predictions, sentiment_labels)\n\u001b[1;32m    126\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (f1_score \u001b[38;5;241m+\u001b[39m acc_score) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m}\n",
      "File \u001b[0;32m~/pavlov/hacks/gagarin/hakaton-gagarin-sentiment_interface/pybooks/../src/t5/utils.py:104\u001b[0m, in \u001b[0;36mevaluate_f1\u001b[0;34m(predictions, labels)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_f1\u001b[39m(predictions, labels):\n\u001b[1;32m    103\u001b[0m     f1_metric \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m     f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mf1_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1_score[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/evaluate/module.py:450\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/evaluate/module.py:515\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(column) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    514\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_nested_string_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format[key], column[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 515\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselected_feature_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwrite_batch(batch)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "File \u001b[0;32m~/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/datasets/features/features.py:1923\u001b[0m, in \u001b[0;36mFeatures.encode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1922\u001b[0m     column \u001b[38;5;241m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1923\u001b[0m     encoded_batch[key] \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mencode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/datasets/features/features.py:1923\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1922\u001b[0m     column \u001b[38;5;241m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1923\u001b[0m     encoded_batch[key] \u001b[38;5;241m=\u001b[39m [\u001b[43mencode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/datasets/features/features.py:1300\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;66;03m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image, ClassLabel, TranslationVariableLanguages, Value, _ArrayXD)):\n\u001b[0;32m-> 1300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/.mlspace/envs/sbs_gen/lib/python3.11/site-packages/datasets/features/features.py:515\u001b[0m, in \u001b[0;36mValue.encode_example\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(value)\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_integer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_type):\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_floating(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_type):\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(value)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'av'"
     ]
    }
   ],
   "source": [
    "# [pin]\n",
    "\n",
    "evaluate_metric(\n",
    "    company_predictions=ldf[\"pcomp\"].tolist(),\n",
    "    company_labels=ldf[\"tcomp\"].tolist(),\n",
    "    sentiment_predictions=ldf[\"psent\"].tolist(),\n",
    "    sentiment_labels=ldf[\"tsent\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-sbs_gen]",
   "language": "python",
   "name": "conda-env-.mlspace-sbs_gen-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
