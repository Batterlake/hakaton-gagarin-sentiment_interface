{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16604</th>\n",
       "      <td>ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª ‚Äî —ç—Ñ—Ñ–µ–∫—Ç –æ—Ç –æ—Ç–º–µ...</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16605</th>\n",
       "      <td>ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª: 3-–π –∫–≤. 2023 –≥....</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16606</th>\n",
       "      <td>ü™® –ú–µ—á–µ–ª: –∞–∫—Ü–∏–∏ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —Ä–æ—Å—Ç–∞ —Å–≤—ã—à–µ 90% –¥...</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16607</th>\n",
       "      <td>ü™® –ú–µ—á–µ–ª: –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º. –í–∑–≥–ª—è–¥ –ë–ö–°  –ú—ã –ø...</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16608</th>\n",
       "      <td>ü´∂ –ê–§–ö –°–∏—Å—Ç–µ–º–∞ –æ–±–µ—â–∞–µ—Ç –¥–∏–≤—ã. –í–µ—Ä–∏–º?  –û—Å–Ω–æ–≤–∞—Ç–µ–ª—å...</td>\n",
       "      <td>26</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text target_text  prefix\n",
       "16604  ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª ‚Äî —ç—Ñ—Ñ–µ–∫—Ç –æ—Ç –æ—Ç–º–µ...          99  clsorg\n",
       "16605  ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª: 3-–π –∫–≤. 2023 –≥....          99  clsorg\n",
       "16606  ü™® –ú–µ—á–µ–ª: –∞–∫—Ü–∏–∏ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —Ä–æ—Å—Ç–∞ —Å–≤—ã—à–µ 90% –¥...          99  clsorg\n",
       "16607  ü™® –ú–µ—á–µ–ª: –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º. –í–∑–≥–ª—è–¥ –ë–ö–°  –ú—ã –ø...          99  clsorg\n",
       "16608  ü´∂ –ê–§–ö –°–∏—Å—Ç–µ–º–∞ –æ–±–µ—â–∞–µ—Ç –¥–∏–≤—ã. –í–µ—Ä–∏–º?  –û—Å–Ω–æ–≤–∞—Ç–µ–ª—å...          26  clsorg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Local File System\n",
    "file_path = \"../data/data.csv\"\n",
    "root_path = \"../data/\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"prefix\"] = \"clsorg\"\n",
    "df = df.rename({\"message\": \"input_text\", \"label\": \"target_text\"}, axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "m_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        source_max_token_length: int = 396,\n",
    "        target_max_token_length: int = 32,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_length = source_max_token_length\n",
    "        self.target_max_token_length = target_max_token_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        source_encoding = tokenizer(\n",
    "            data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            max_length=self.source_max_token_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            # truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_encoding = tokenizer(\n",
    "            data_row[\"target_text\"],\n",
    "            max_length=self.target_max_token_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return dict(\n",
    "            input_text=data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            target_text=data_row[\"target_text\"],\n",
    "            input_ids=source_encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=source_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataModel(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        batch_size: int = 8,\n",
    "        source_max_token_length=396,\n",
    "        target_max_token_length=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_token_length = source_max_token_length\n",
    "        self.target_max_token_length = target_max_token_length\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = NERDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_length,\n",
    "            self.target_max_token_length,\n",
    "        )\n",
    "\n",
    "        self.test_dataset = NERDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_length,\n",
    "            self.target_max_token_length,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=10\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "data_module = NERDataModel(train_df, test_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            m_name, return_dict=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/worker/workspace/hakaton-gagarin-sentiment_interface/.conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"ner\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a4b5e53a77401f866b49814a455ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd1927531a5439aba8a72f9718afb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26eeca01bdd4402baee8d11b44e9cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 98: 'val_loss' reached 1.25994 (best 1.25994), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6c461cb8e346fdbb76743c91148796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 196: 'val_loss' reached 1.04948 (best 1.04948), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ea43fa366b40b897f258d9ca029bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 294: 'val_loss' reached 0.97783 (best 0.97783), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0845cdde2e34cadbfae193024d9ba00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 392: 'val_loss' reached 0.95075 (best 0.95075), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffc5175b64e43558f291e59c0917ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 490: 'val_loss' reached 0.95019 (best 0.95019), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620f590373c24a69898c14cd7f976a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 588: 'val_loss' was not in top 1\n",
      "/home/worker/workspace/hakaton-gagarin-sentiment_interface/.conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = NERModel.load_from_checkpoint(\"checkpoints/ner-v4.ckpt\")\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(data_row):\n",
    "    with torch.no_grad():\n",
    "        source_encoding = tokenizer(\n",
    "            data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            max_length=396,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        generated_ids = trained_model.model.generate(\n",
    "            input_ids=source_encoding[\"input_ids\"].cuda(),\n",
    "            attention_mask=source_encoding[\"attention_mask\"].cuda(),\n",
    "            num_beams=3,\n",
    "            max_length=80,\n",
    "            repetition_penalty=1.0,\n",
    "            early_stopping=True,\n",
    "            use_cache=True,\n",
    "        ).cpu()\n",
    "\n",
    "        preds = [\n",
    "            tokenizer.decode(\n",
    "                generated_id,\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True,\n",
    "            )\n",
    "            for generated_id in generated_ids\n",
    "        ]\n",
    "\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_answer_batched(data: pd.DataFrame, batch_size: int = 64):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for name, batch in tqdm(data.groupby(np.arange(len(data)) // batch_size)):\n",
    "            source_encoding = tokenizer(\n",
    "                (batch[\"prefix\"] + \": \" + batch[\"input_text\"]).tolist(),\n",
    "                max_length=396,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                add_special_tokens=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "            generated_ids = trained_model.model.generate(\n",
    "                input_ids=source_encoding[\"input_ids\"].cuda(),\n",
    "                attention_mask=source_encoding[\"attention_mask\"].cuda(),\n",
    "                num_beams=3,\n",
    "                max_length=80,\n",
    "                repetition_penalty=1.0,\n",
    "                early_stopping=True,\n",
    "                use_cache=True,\n",
    "            ).cpu()\n",
    "\n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            predictions.append(preds)\n",
    "\n",
    "    return sum(predictions, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c42f2bc633b40f097ac74c0a7e3c98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = generate_answer_batched(test_df, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4232, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = test_df.copy()\n",
    "res_df.drop(columns=[\"target_text\"], inplace=True)\n",
    "res_df[\"predictions\"] = predictions\n",
    "res_df[\"predictions\"] = res_df[\"predictions\"].str.split(\";\")\n",
    "res_df = res_df.explode(\"predictions\")\n",
    "res_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4812, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = test_df.copy()\n",
    "exp_df[\"target_text\"] = exp_df[\"target_text\"].str.split(\";\")\n",
    "exp_df = exp_df.explode(\"target_text\")\n",
    "exp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_df = pd.merge(\n",
    "    exp_df[[\"input_text\", \"target_text\"]],\n",
    "    res_df[[\"input_text\", \"predictions\"]],\n",
    "    on=\"input_text\",\n",
    "    how=\"left\",\n",
    ").fillna(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11387</th>\n",
       "      <td>–ü–æ BANEP –∫—Å—Ç–∞ –ø–æ—á—Ç–∏ –∑–∞–∫—Ä—ã–ª–∏ –¥–∏–≤–≥—ç–ø.  –ù–∏ –Ω–∞ —á—Ç–æ...</td>\n",
       "      <td>25</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>#—Ä–∏–∫–æ–º_–æ–±–∑–æ—Ä—ã  üìÇ ¬´–õ–µ–Ω—Ç–∞¬ª ‚Äî –∫—Ä—É–ø–Ω–µ–π—à–∞—è —Å–µ—Ç—å –≥–∏–ø...</td>\n",
       "      <td>229</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15554</th>\n",
       "      <td>üìÜ #–ö–∞–ª–µ–Ω–¥–∞—Ä—å –Ω–µ–¥–µ–ª–∏: 24-28 –∏—é–ª—è   –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫,...</td>\n",
       "      <td>231</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>#VTBR ‚ö° –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –í–¢–ë –∑–∞ 1–∫–≤2023 –æ—Ü–µ–Ω–∏–≤–∞–µ...</td>\n",
       "      <td>7</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>????????#ipo #FLOT –í–¨–Æ–ì–ò–ù: –°–û–í–ö–û–ú–§–õ–û–¢ –û–¶–ï–ù–ï–ù 2...</td>\n",
       "      <td>157</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>\"–õ—å–≥–æ—Ç–Ω–∞—è –∏–ø–æ—Ç–µ–∫–∞ –∂–∏–≤–µ—Ç!    –ú–û–°–ö–í–ê, 4 —Å–µ–Ω—Ç—è–±—Ä—è...</td>\n",
       "      <td>218</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>????#–±—Ä–æ–∫–µ—Ä—ã—Ä—Ñ #—Ñ–∏–Ω–∏–Ω–¥—É—Å—Ç—Ä–∏—è—Ä—Ñ #VTBR –í 2018 –≥–æ...</td>\n",
       "      <td>7</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14183</th>\n",
       "      <td>üá∑üá∫#MTSS #ipo –ê–∫—Ü–∏–æ–Ω–µ—Ä—ã –ú–¢–°-–±–∞–Ω–∫–∞ –≤–æ–∑–¥–µ—Ä–∂–∞–ª–∏—Å—å ...</td>\n",
       "      <td>100</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>TRCN - –î–ò–í–ò–î–ï–ù–î–´ –°–û–í–ï–¢ –î–ò–†–ï–ö–¢–û–†–û–í –¢–†–ê–ù–°–ö–û–ù–¢–ï–ô–ù...</td>\n",
       "      <td>190</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14189</th>\n",
       "      <td>üá∑üá∫#MTSS #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  19 –º–∞—è - –ú–¢–°  –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã...</td>\n",
       "      <td>100</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11335</th>\n",
       "      <td>–ü–û–ö–£–ü–ö–ê –ê–ö–¶–ò–ô   –†–û–°–¢–ï–õ–ï–ö–û–ú  –¶–µ–ª–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏...</td>\n",
       "      <td>142</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13262</th>\n",
       "      <td>‚Ä¢ –ü–µ—Ä–µ–µ–∑–¥ –≤ —Ä–æ—Å—Å–∏–π—Å–∫—É—é —é—Ä–∏—Å–¥–∏–∫—Ü–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏...</td>\n",
       "      <td>231</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>üü¢ –ù–æ–≤–æ—Å—Ç–∏ –∫ —ç—Ç–æ–º—É —á–∞—Å—É  ‚ö™Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —ç–∫—Å–ø...</td>\n",
       "      <td>163</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12793</th>\n",
       "      <td>‚Äã‚Äã–û–ø—è—Ç—å –¥–æ–ø–∫–∞üî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìâ–í–¢–ë -1.4% –û...</td>\n",
       "      <td>218</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>#RUAL #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –†–£–°–ê–õ - –ü–†–û–ò–ó–í–û–î–°–¢–í–û –ê–õ–Æ–ú–ò–ù–ò...</td>\n",
       "      <td>11</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15487</th>\n",
       "      <td>üí∏ –ì–∏–ø–µ—Ä–∏–Ω—Ñ–ª—è—Ü–∏—è - —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å? –ö–∞–∫ –∑–∞—â–∏—Ç–∏—Ç—å...</td>\n",
       "      <td>112</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14151</th>\n",
       "      <td>üá∑üá∫#MOEX #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –±–∏—Ä–∂–∞ –ø–æ–¥–≤–µ–ª–∞ ...</td>\n",
       "      <td>103</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>\"#CHMF –ü–ê–û \"\"–°–µ–≤–µ—Ä—Å—Ç–∞–ª—å\"\" –ø–æ–¥–ø–∏—Å–∞–ª–æ –æ–±—è–∑—ã–≤–∞—é—â–µ...</td>\n",
       "      <td>152</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>–í 2020 –≥–æ–¥—É –≤ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π, –ê—Å—Ç—Ä–∞—Ö–∞–Ω—Å–∫–æ–π –∏ –ö–∏—Ä–æ–≤...</td>\n",
       "      <td>225</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>\"??–ò—Ä–∫—É—Ç. –ù–∞ –≤–∑–ª–µ—Ç!  –†–µ—Ñ–æ—Ä–º–∞ –∞–≤–∏–∞—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–π ...</td>\n",
       "      <td>120</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text target_text  prefix  \\\n",
       "11387  –ü–æ BANEP –∫—Å—Ç–∞ –ø–æ—á—Ç–∏ –∑–∞–∫—Ä—ã–ª–∏ –¥–∏–≤–≥—ç–ø.  –ù–∏ –Ω–∞ —á—Ç–æ...          25  clsorg   \n",
       "6076   #—Ä–∏–∫–æ–º_–æ–±–∑–æ—Ä—ã  üìÇ ¬´–õ–µ–Ω—Ç–∞¬ª ‚Äî –∫—Ä—É–ø–Ω–µ–π—à–∞—è —Å–µ—Ç—å –≥–∏–ø...         229  clsorg   \n",
       "15554  üìÜ #–ö–∞–ª–µ–Ω–¥–∞—Ä—å –Ω–µ–¥–µ–ª–∏: 24-28 –∏—é–ª—è   –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫,...         231  clsorg   \n",
       "5723   #VTBR ‚ö° –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –í–¢–ë –∑–∞ 1–∫–≤2023 –æ—Ü–µ–Ω–∏–≤–∞–µ...           7  clsorg   \n",
       "8193   ????????#ipo #FLOT –í–¨–Æ–ì–ò–ù: –°–û–í–ö–û–ú–§–õ–û–¢ –û–¶–ï–ù–ï–ù 2...         157  clsorg   \n",
       "2788   \"–õ—å–≥–æ—Ç–Ω–∞—è –∏–ø–æ—Ç–µ–∫–∞ –∂–∏–≤–µ—Ç!    –ú–û–°–ö–í–ê, 4 —Å–µ–Ω—Ç—è–±—Ä—è...         218  clsorg   \n",
       "7762   ????#–±—Ä–æ–∫–µ—Ä—ã—Ä—Ñ #—Ñ–∏–Ω–∏–Ω–¥—É—Å—Ç—Ä–∏—è—Ä—Ñ #VTBR –í 2018 –≥–æ...           7  clsorg   \n",
       "14183  üá∑üá∫#MTSS #ipo –ê–∫—Ü–∏–æ–Ω–µ—Ä—ã –ú–¢–°-–±–∞–Ω–∫–∞ –≤–æ–∑–¥–µ—Ä–∂–∞–ª–∏—Å—å ...         100  clsorg   \n",
       "9492   TRCN - –î–ò–í–ò–î–ï–ù–î–´ –°–û–í–ï–¢ –î–ò–†–ï–ö–¢–û–†–û–í –¢–†–ê–ù–°–ö–û–ù–¢–ï–ô–ù...         190  clsorg   \n",
       "14189  üá∑üá∫#MTSS #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  19 –º–∞—è - –ú–¢–°  –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã...         100  clsorg   \n",
       "11335  –ü–û–ö–£–ü–ö–ê –ê–ö–¶–ò–ô   –†–û–°–¢–ï–õ–ï–ö–û–ú  –¶–µ–ª–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏...         142  clsorg   \n",
       "13262  ‚Ä¢ –ü–µ—Ä–µ–µ–∑–¥ –≤ —Ä–æ—Å—Å–∏–π—Å–∫—É—é —é—Ä–∏—Å–¥–∏–∫—Ü–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏...         231  clsorg   \n",
       "16378  üü¢ –ù–æ–≤–æ—Å—Ç–∏ –∫ —ç—Ç–æ–º—É —á–∞—Å—É  ‚ö™Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —ç–∫—Å–ø...         163  clsorg   \n",
       "12793  ‚Äã‚Äã–û–ø—è—Ç—å –¥–æ–ø–∫–∞üî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìâ–í–¢–ë -1.4% –û...         218  clsorg   \n",
       "5379   #RUAL #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –†–£–°–ê–õ - –ü–†–û–ò–ó–í–û–î–°–¢–í–û –ê–õ–Æ–ú–ò–ù–ò...          11  clsorg   \n",
       "15487  üí∏ –ì–∏–ø–µ—Ä–∏–Ω—Ñ–ª—è—Ü–∏—è - —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å? –ö–∞–∫ –∑–∞—â–∏—Ç–∏—Ç—å...         112  clsorg   \n",
       "14151  üá∑üá∫#MOEX #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ú–æ—Å–∫–æ–≤—Å–∫–∞—è –±–∏—Ä–∂–∞ –ø–æ–¥–≤–µ–ª–∞ ...         103  clsorg   \n",
       "185    \"#CHMF –ü–ê–û \"\"–°–µ–≤–µ—Ä—Å—Ç–∞–ª—å\"\" –ø–æ–¥–ø–∏—Å–∞–ª–æ –æ–±—è–∑—ã–≤–∞—é—â–µ...         152  clsorg   \n",
       "9930   –í 2020 –≥–æ–¥—É –≤ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π, –ê—Å—Ç—Ä–∞—Ö–∞–Ω—Å–∫–æ–π –∏ –ö–∏—Ä–æ–≤...         225  clsorg   \n",
       "1720   \"??–ò—Ä–∫—É—Ç. –ù–∞ –≤–∑–ª–µ—Ç!  –†–µ—Ñ–æ—Ä–º–∞ –∞–≤–∏–∞—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–π ...         120  clsorg   \n",
       "\n",
       "      predictions  \n",
       "11387          25  \n",
       "6076          218  \n",
       "15554         235  \n",
       "5723            7  \n",
       "8193          157  \n",
       "2788          230  \n",
       "7762            7  \n",
       "14183         100  \n",
       "9492          190  \n",
       "14189         100  \n",
       "11335         142  \n",
       "13262         220  \n",
       "16378         236  \n",
       "12793          33  \n",
       "5379           11  \n",
       "15487         225  \n",
       "14151         103  \n",
       "185           152  \n",
       "9930          225  \n",
       "1720          149  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf = test_df.copy()\n",
    "ldf[\"predictions\"] = pd.Series(predictions).str.split(\";\", expand=True)[0].values\n",
    "ldf[\"target_text\"] = ldf[\"target_text\"].str.split(\";\", expand=True)[0].values\n",
    "ldf.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6451461823244122}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "final_score = metric.compute(\n",
    "    predictions=ldf[\"predictions\"].tolist(),\n",
    "    references=ldf[\"target_text\"].tolist(),\n",
    "    average=\"weighted\",\n",
    ")\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
