{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16604</th>\n",
       "      <td>ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª ‚Äî —ç—Ñ—Ñ–µ–∫—Ç –æ—Ç –æ—Ç–º–µ...</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16605</th>\n",
       "      <td>ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª: 3-–π –∫–≤. 2023 –≥....</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16606</th>\n",
       "      <td>ü™® –ú–µ—á–µ–ª: –∞–∫—Ü–∏–∏ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —Ä–æ—Å—Ç–∞ —Å–≤—ã—à–µ 90% –¥...</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16607</th>\n",
       "      <td>ü™® –ú–µ—á–µ–ª: –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º. –í–∑–≥–ª—è–¥ –ë–ö–°  –ú—ã –ø...</td>\n",
       "      <td>99</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16608</th>\n",
       "      <td>ü´∂ –ê–§–ö –°–∏—Å—Ç–µ–º–∞ –æ–±–µ—â–∞–µ—Ç –¥–∏–≤—ã. –í–µ—Ä–∏–º?  –û—Å–Ω–æ–≤–∞—Ç–µ–ª—å...</td>\n",
       "      <td>26</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text target_text  prefix\n",
       "16604  ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª ‚Äî —ç—Ñ—Ñ–µ–∫—Ç –æ—Ç –æ—Ç–º–µ...          99  clsorg\n",
       "16605  ü™® –í–∑–≥–ª—è–¥ –Ω–∞ –∫–æ–º–ø–∞–Ω–∏—é: ¬´–ú–µ—á–µ–ª¬ª: 3-–π –∫–≤. 2023 –≥....          99  clsorg\n",
       "16606  ü™® –ú–µ—á–µ–ª: –∞–∫—Ü–∏–∏ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —Ä–æ—Å—Ç–∞ —Å–≤—ã—à–µ 90% –¥...          99  clsorg\n",
       "16607  ü™® –ú–µ—á–µ–ª: –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º. –í–∑–≥–ª—è–¥ –ë–ö–°  –ú—ã –ø...          99  clsorg\n",
       "16608  ü´∂ –ê–§–ö –°–∏—Å—Ç–µ–º–∞ –æ–±–µ—â–∞–µ—Ç –¥–∏–≤—ã. –í–µ—Ä–∏–º?  –û—Å–Ω–æ–≤–∞—Ç–µ–ª—å...          26  clsorg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Local File System\n",
    "file_path = \"../data/data.csv\"\n",
    "root_path = \"../data/\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"prefix\"] = \"clsorg\"\n",
    "df = df.rename({\"message\": \"input_text\", \"label\": \"target_text\"}, axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "m_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        source_max_token_length: int = 396,\n",
    "        target_max_token_length: int = 32,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_length = source_max_token_length\n",
    "        self.target_max_token_length = target_max_token_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        source_encoding = tokenizer(\n",
    "            data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            max_length=self.source_max_token_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            # truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_encoding = tokenizer(\n",
    "            data_row[\"target_text\"],\n",
    "            max_length=self.target_max_token_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return dict(\n",
    "            input_text=data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            target_text=data_row[\"target_text\"],\n",
    "            input_ids=source_encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=source_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataModel(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        batch_size: int = 8,\n",
    "        source_max_token_length=396,\n",
    "        target_max_token_length=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_token_length = source_max_token_length\n",
    "        self.target_max_token_length = target_max_token_length\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = NERDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_length,\n",
    "            self.target_max_token_length,\n",
    "        )\n",
    "\n",
    "        self.test_dataset = NERDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_length,\n",
    "            self.target_max_token_length,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=10\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "data_module = NERDataModel(train_df, test_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            m_name, return_dict=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"ner\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a4b5e53a77401f866b49814a455ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd1927531a5439aba8a72f9718afb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26eeca01bdd4402baee8d11b44e9cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 98: 'val_loss' reached 1.25994 (best 1.25994), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6c461cb8e346fdbb76743c91148796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 196: 'val_loss' reached 1.04948 (best 1.04948), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ea43fa366b40b897f258d9ca029bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 294: 'val_loss' reached 0.97783 (best 0.97783), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0845cdde2e34cadbfae193024d9ba00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 392: 'val_loss' reached 0.95075 (best 0.95075), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffc5175b64e43558f291e59c0917ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 490: 'val_loss' reached 0.95019 (best 0.95019), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v4.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620f590373c24a69898c14cd7f976a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 588: 'val_loss' was not in top 1\n",
      "/home/worker/workspace/hakaton-gagarin-sentiment_interface/.conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = NERModel.load_from_checkpoint(\"checkpoints/ner-v4.ckpt\")\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(data_row):\n",
    "    with torch.no_grad():\n",
    "        source_encoding = tokenizer(\n",
    "            data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            max_length=396,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        generated_ids = trained_model.model.generate(\n",
    "            input_ids=source_encoding[\"input_ids\"].cuda(),\n",
    "            attention_mask=source_encoding[\"attention_mask\"].cuda(),\n",
    "            num_beams=3,\n",
    "            max_length=80,\n",
    "            repetition_penalty=1.0,\n",
    "            early_stopping=True,\n",
    "            use_cache=True,\n",
    "        ).cpu()\n",
    "\n",
    "        preds = [\n",
    "            tokenizer.decode(\n",
    "                generated_id,\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True,\n",
    "            )\n",
    "            for generated_id in generated_ids\n",
    "        ]\n",
    "\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_answer_batched(data: pd.DataFrame, batch_size: int = 64):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for name, batch in tqdm(data.groupby(np.arange(len(data)) // batch_size)):\n",
    "            source_encoding = tokenizer(\n",
    "                (batch[\"prefix\"] + \": \" + batch[\"input_text\"]).tolist(),\n",
    "                max_length=396,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                add_special_tokens=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "            generated_ids = trained_model.model.generate(\n",
    "                input_ids=source_encoding[\"input_ids\"].cuda(),\n",
    "                attention_mask=source_encoding[\"attention_mask\"].cuda(),\n",
    "                num_beams=3,\n",
    "                max_length=80,\n",
    "                repetition_penalty=1.0,\n",
    "                early_stopping=True,\n",
    "                use_cache=True,\n",
    "            ).cpu()\n",
    "\n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            predictions.append(preds)\n",
    "\n",
    "    return sum(predictions, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d64a0c6980432aba8bdfc28e262d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = generate_answer_batched(test_df, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14448</th>\n",
       "      <td>üá∑üá∫#TRNFP #ROSN #—Å—É–¥ –°—É–¥ –ø—Ä–µ–∫—Ä–∞—Ç–∏–ª –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ...</td>\n",
       "      <td>175;112</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>\"üèÅ 14 —Ñ–µ–≤—Ä–∞–ª—è: –ò—Ç–æ–≥–∏ –¥–Ω—è   üá∫üá∏ –î–∞–Ω–Ω—ã–µ –ø–æ –∏–Ω—Ñ–ª—è—Ü...</td>\n",
       "      <td>90;152;116</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>CHMF –°–ï–í–ï–†–°–¢–ê–õ–¨ –ü–õ–ê–ù–ò–†–£–ï–¢ –í –ë–õ–ò–ñ–ê–ô–®–ò–ï 5 –õ–ï–¢ –°–û...</td>\n",
       "      <td>152</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14175</th>\n",
       "      <td>üá∑üá∫#MTSS  –ú–¢–° –ø–æ–∑–≤–æ–ª–∏—Ç –±–∏–∑–Ω–µ—Å—É —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–µ—Ä–≤–∏—Å...</td>\n",
       "      <td>100</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>ENPG +5% intraday</td>\n",
       "      <td>12</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16089</th>\n",
       "      <td>üò± –ß—Ç–æ –Ω–∞—Å –∂–¥–µ—Ç –∑–∞–≤—Ç—Ä–∞?  –ö–æ—à–º–∞—Ä –ø–æ–¥ –∫–æ–Ω–µ—Ü –Ω–µ–¥–µ–ª...</td>\n",
       "      <td>103</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15437</th>\n",
       "      <td>üí•üá∑üá∫#–∞–≤–∏–∞ #—Ä–æ—Å—Å–∏—è #ALRS –û–±—ä–µ–º –ø–∞—Å—Å–∞–∂–∏—Ä—Å–∫–∏—Ö –ø–µ—Ä–µ...</td>\n",
       "      <td>4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15213</th>\n",
       "      <td>üí•üá∑üá∫#MRKU = +5% = –º–∞–∫—Å –∑–∞ 7 –º–µ—Å</td>\n",
       "      <td>17</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10286</th>\n",
       "      <td>–ì–ª–∞–≤–Ω–æ–µ –∫ –æ—Ç–∫—Ä—ã—Ç–∏—é —Å—Ä–µ–¥—ã (07.06): #–±—Ä–∏—Ñ–∏–Ω–≥  üìå ...</td>\n",
       "      <td>115</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>????¬´–í–¢–ë¬ª (VTBR) –ü–û–ö–£–ü–ê–¢–¨??  –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –≥–æ...</td>\n",
       "      <td>7</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>–ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—É—é —Å–∫–∏–¥–∫—É 8% –æ—Ç RDV PREMI...</td>\n",
       "      <td>223</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13896</th>\n",
       "      <td>üá∑üá∫#AFLT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ì–†–£–ü–ü–ê –ê–≠–†–û–§–õ–û–¢ –°–û–ö–†–ê–¢–ò–õ–ê...</td>\n",
       "      <td>32</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12710</th>\n",
       "      <td>‚Äã‚Äã–ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏ –ø–æ –∏—Ç–æ–≥–∞–º –Ω–µ–¥–µ–ª–∏: +0,36%  –ò—Ç...</td>\n",
       "      <td>230</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>NLMK - –ü–†–û–ò–ó–í–û–î–°–¢–í–ï–ù–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ù–õ–ú–ö –≤ 3 –∫–≤...</td>\n",
       "      <td>116</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>\"????–í–û–°–ö–†–ï–°–ù–´–ô OUTLOOK: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ...</td>\n",
       "      <td>218</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>??????#FIXP #–∏–Ω—Å–∞–π–¥–µ—Ä  Fix Price Group Ltd- –∏–∑...</td>\n",
       "      <td>219</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>#UPRO UPRO FORTUM –ò–ù–ò–¶–ò–ò–†–û–í–ê–õ –ê–†–ë–ò–¢–†–ê–ñ–ù–û–ï –î–ï–õ–û...</td>\n",
       "      <td>199</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16120</th>\n",
       "      <td>üö¢ –í –°–µ–≤–µ—Ä–Ω—ã–π –º–æ—Ä—Å–∫–æ–π –ø—É—Ç—å –≤–ª–æ–∂–∞—Ç —Ç—Ä–∏–ª–ª–∏–æ–Ω—ã —Ä—É–±...</td>\n",
       "      <td>157</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13340</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#ALRS #–∞–ª–º–∞–∑—ã –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ —Ü–µ–Ω —Å–æ–∫—Ä–∞...</td>\n",
       "      <td>4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>\"üõ¢üá∑üá∫#NVTK \"\"–ù–æ–≤–∞—Ç—ç–∫\"\" –∂–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–æ–±—ã—á–∏ –≥...</td>\n",
       "      <td>115</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text target_text  prefix  \\\n",
       "14448  üá∑üá∫#TRNFP #ROSN #—Å—É–¥ –°—É–¥ –ø—Ä–µ–∫—Ä–∞—Ç–∏–ª –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ...     175;112  clsorg   \n",
       "3842   \"üèÅ 14 —Ñ–µ–≤—Ä–∞–ª—è: –ò—Ç–æ–≥–∏ –¥–Ω—è   üá∫üá∏ –î–∞–Ω–Ω—ã–µ –ø–æ –∏–Ω—Ñ–ª—è—Ü...  90;152;116  clsorg   \n",
       "9054   CHMF –°–ï–í–ï–†–°–¢–ê–õ–¨ –ü–õ–ê–ù–ò–†–£–ï–¢ –í –ë–õ–ò–ñ–ê–ô–®–ò–ï 5 –õ–ï–¢ –°–û...         152  clsorg   \n",
       "14175  üá∑üá∫#MTSS  –ú–¢–° –ø–æ–∑–≤–æ–ª–∏—Ç –±–∏–∑–Ω–µ—Å—É —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–µ—Ä–≤–∏—Å...         100  clsorg   \n",
       "9070                                   ENPG +5% intraday          12  clsorg   \n",
       "16089  üò± –ß—Ç–æ –Ω–∞—Å –∂–¥–µ—Ç –∑–∞–≤—Ç—Ä–∞?  –ö–æ—à–º–∞—Ä –ø–æ–¥ –∫–æ–Ω–µ—Ü –Ω–µ–¥–µ–ª...         103  clsorg   \n",
       "15437  üí•üá∑üá∫#–∞–≤–∏–∞ #—Ä–æ—Å—Å–∏—è #ALRS –û–±—ä–µ–º –ø–∞—Å—Å–∞–∂–∏—Ä—Å–∫–∏—Ö –ø–µ—Ä–µ...           4  clsorg   \n",
       "15213                     üí•üá∑üá∫#MRKU = +5% = –º–∞–∫—Å –∑–∞ 7 –º–µ—Å          17  clsorg   \n",
       "10286  –ì–ª–∞–≤–Ω–æ–µ –∫ –æ—Ç–∫—Ä—ã—Ç–∏—é —Å—Ä–µ–¥—ã (07.06): #–±—Ä–∏—Ñ–∏–Ω–≥  üìå ...         115  clsorg   \n",
       "8314   ????¬´–í–¢–ë¬ª (VTBR) –ü–û–ö–£–ü–ê–¢–¨??  –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –≥–æ...           7  clsorg   \n",
       "9751   –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—É—é —Å–∫–∏–¥–∫—É 8% –æ—Ç RDV PREMI...         223  clsorg   \n",
       "13896  üá∑üá∫#AFLT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ì–†–£–ü–ü–ê –ê–≠–†–û–§–õ–û–¢ –°–û–ö–†–ê–¢–ò–õ–ê...          32  clsorg   \n",
       "12710  ‚Äã‚Äã–ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏ –ø–æ –∏—Ç–æ–≥–∞–º –Ω–µ–¥–µ–ª–∏: +0,36%  –ò—Ç...         230  clsorg   \n",
       "9287   NLMK - –ü–†–û–ò–ó–í–û–î–°–¢–í–ï–ù–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ù–õ–ú–ö –≤ 3 –∫–≤...         116  clsorg   \n",
       "1557   \"????–í–û–°–ö–†–ï–°–ù–´–ô OUTLOOK: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ...         218  clsorg   \n",
       "7895   ??????#FIXP #–∏–Ω—Å–∞–π–¥–µ—Ä  Fix Price Group Ltd- –∏–∑...         219  clsorg   \n",
       "5665   #UPRO UPRO FORTUM –ò–ù–ò–¶–ò–ò–†–û–í–ê–õ –ê–†–ë–ò–¢–†–ê–ñ–ù–û–ï –î–ï–õ–û...         199  clsorg   \n",
       "16120  üö¢ –í –°–µ–≤–µ—Ä–Ω—ã–π –º–æ—Ä—Å–∫–æ–π –ø—É—Ç—å –≤–ª–æ–∂–∞—Ç —Ç—Ä–∏–ª–ª–∏–æ–Ω—ã —Ä—É–±...         157  clsorg   \n",
       "13340  ‚ö†Ô∏èüá∑üá∫#ALRS #–∞–ª–º–∞–∑—ã –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ —Ü–µ–Ω —Å–æ–∫—Ä–∞...           4  clsorg   \n",
       "4140   \"üõ¢üá∑üá∫#NVTK \"\"–ù–æ–≤–∞—Ç—ç–∫\"\" –∂–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–æ–±—ã—á–∏ –≥...         115  clsorg   \n",
       "\n",
       "      predictions  \n",
       "14448         175  \n",
       "3842          150  \n",
       "9054          152  \n",
       "14175         100  \n",
       "9070           12  \n",
       "16089         150  \n",
       "15437           4  \n",
       "15213         149  \n",
       "10286         115  \n",
       "8314            7  \n",
       "9751          177  \n",
       "13896          32  \n",
       "12710         220  \n",
       "9287          116  \n",
       "1557          103  \n",
       "7895          219  \n",
       "5665          199  \n",
       "16120         225  \n",
       "13340           4  \n",
       "4140          115  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m prs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[^\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md]+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m lbs \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      7\u001b[0m lbs\n",
      "\u001b[0;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "prs = (\n",
    "    pd.Series(predictions)\n",
    "    .str.replace(r\"[^\\d]+\", \"0\", regex=True)\n",
    "    .values.astype(np.int32)\n",
    ")\n",
    "lbs = test_df[\"target_text\"].str.split(\";\", expand=True)[0].values.astype(int)\n",
    "lbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6069452264215539}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "final_score = metric.compute(predictions=prs, references=lbs, average=\"weighted\")\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
