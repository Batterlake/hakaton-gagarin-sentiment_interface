{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def seed_everything(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>‚Äã‚ÄãYouTube —Ö–æ—Ç—è—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–µ–¥—è –≤—Å–µ—Ö –≤ ...</td>\n",
       "      <td>223-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>üßë‚Äçüíª –°–æ—Ñ—Ç–ª–∞–π–Ω –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º—É –º–æ—Ç–∏–≤–∞—Ü–∏–∏ —Å–æ—Ç...</td>\n",
       "      <td>237-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#PLZL #–¥–∏–≤–∏–¥–µ–Ω–¥ —Å–¥ –ü–æ–ª—é—Å:  –Ω–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å ...</td>\n",
       "      <td>127-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>üü¢ –ü–æ–ª—é—Å ‚Äî —Å–∞–º–∞—è –Ω–∞–¥–µ–∂–Ω–∞—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è –≤ —Ä–æ—Å—Å–∏–π—Å–∫...</td>\n",
       "      <td>127-4;127-5</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –ü–æ–ª—é—Å–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –Ω–µ –≤—ã–ø–ª–∞—á...</td>\n",
       "      <td>127-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>üá∑üá∫#FEES #—Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è  ¬´–†–æ—Å—Å–µ—Ç–∏¬ª —Å–æ–∑–¥–∞–¥—É—Ç —Ü–∏—Ñ—Ä...</td>\n",
       "      <td>186-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>üí•üá∑üá∫#MTLR = +5%</td>\n",
       "      <td>99-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –±–∞–Ω–∫–æ–≤—Å–∫–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞ –≤ –º–∞—Ä—Ç–µ 202...</td>\n",
       "      <td>150-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>\"üá∑üá∫#SMLT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  \"\"–°–∞–º–æ–ª–µ—Ç\"\" –≤ IV –∫–≤. —É–≤–µ...</td>\n",
       "      <td>56-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>\"üá∑üá∫#BELU \"\"–ë–µ–ª—É–≥–∞ –ì—Ä—É–ø–ø\"\" —Å–º–µ–Ω–∏–ª–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ ...</td>\n",
       "      <td>36-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>–ò–Ω–¥–µ–∫—Å –æ–ø—è—Ç—å –¥–æ—Ä–æ–≥–æ–π (–ø–æ –≤–µ—Ä—Å–∏–∏ —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª...</td>\n",
       "      <td>25-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#POLY  –ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è —Å–∞–Ω–∫—Ü–∏–π –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö ...</td>\n",
       "      <td>235-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>‚Äã–ü—Ä–∏–≤—ã–∫–∞–π –∂–∏—Ç—å –≤ —Ä—É–±–ª—ë–≤–æ–π –∑–æ–Ω–µüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏...</td>\n",
       "      <td>251-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>\"‚ö†Ô∏èüá∑üá∫#MAGN  –ú–ú–ö –Ω–µ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç buyback –≤ –±–ª–∏–∂–∞–π—à...</td>\n",
       "      <td>90-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ ¬´–¢–∞—Ç–Ω–µ—Ñ—Ç–∏¬ª —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –≤—ã–ø–ª–∞...</td>\n",
       "      <td>163-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>üí•üá∑üá∫#SNGS = –º–∞–∫—Å –∑–∞ 5 –º–µ—Å</td>\n",
       "      <td>160-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>‚Äã‚Äã–í–æ–∑—Ä–æ–∂–¥–µ–Ω–∏–µ –ú.–í–∏–¥–µ–æ ‚óè –î–µ–ª–∏–º–æ–±–∏–ª—å —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª ‚óè...</td>\n",
       "      <td>88-3;273-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>üá∑üá∫#SBER #VTBR #cot  ¬´–°–±–µ—Ä¬ª —Å—Ç–∞–ª —Å–∞–º–æ–π –ø–æ–ø—É–ª—è—Ä–Ω...</td>\n",
       "      <td>150-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>üá∑üá∫#ROSN #event  –ü—É—Ç–∏–Ω –∏ –°–µ—á–∏–Ω 1 –¥–µ–∫–∞–±—Ä—è –ø–æ–æ–±—â–∞...</td>\n",
       "      <td>112-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>–ê–ª—Ä–æ—Å–∞ - –∞–ª–º–∞–∑ –∫–æ—Ç–æ—Ä—ã–π –ª–µ–∂–∏—Ç –Ω–∞ –ø–æ–ª—É. –ê–≤—Ç–æ—Ä: i...</td>\n",
       "      <td>4-5</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  target_text  prefix\n",
       "3538  ‚Äã‚ÄãYouTube —Ö–æ—Ç—è—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–µ–¥—è –≤—Å–µ—Ö –≤ ...        223-4  clsorg\n",
       "7019  üßë‚Äçüíª –°–æ—Ñ—Ç–ª–∞–π–Ω –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º—É –º–æ—Ç–∏–≤–∞—Ü–∏–∏ —Å–æ—Ç...        237-4  clsorg\n",
       "4123  ‚ö†Ô∏èüá∑üá∫#PLZL #–¥–∏–≤–∏–¥–µ–Ω–¥ —Å–¥ –ü–æ–ª—é—Å:  –Ω–µ –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å ...        127-2  clsorg\n",
       "6912  üü¢ –ü–æ–ª—é—Å ‚Äî —Å–∞–º–∞—è –Ω–∞–¥–µ–∂–Ω–∞—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è –≤ —Ä–æ—Å—Å–∏–π—Å–∫...  127-4;127-5  clsorg\n",
       "3164  –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –ü–æ–ª—é—Å–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –Ω–µ –≤—ã–ø–ª–∞—á...        127-2  clsorg\n",
       "4644  üá∑üá∫#FEES #—Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è  ¬´–†–æ—Å—Å–µ—Ç–∏¬ª —Å–æ–∑–¥–∞–¥—É—Ç —Ü–∏—Ñ—Ä...        186-3  clsorg\n",
       "5796                                     üí•üá∑üá∫#MTLR = +5%         99-3  clsorg\n",
       "3315  –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –±–∞–Ω–∫–æ–≤—Å–∫–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞ –≤ –º–∞—Ä—Ç–µ 202...        150-4  clsorg\n",
       "824   \"üá∑üá∫#SMLT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  \"\"–°–∞–º–æ–ª–µ—Ç\"\" –≤ IV –∫–≤. —É–≤–µ...         56-4  clsorg\n",
       "610   \"üá∑üá∫#BELU \"\"–ë–µ–ª—É–≥–∞ –ì—Ä—É–ø–ø\"\" —Å–º–µ–Ω–∏–ª–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ ...         36-3  clsorg\n",
       "2470  –ò–Ω–¥–µ–∫—Å –æ–ø—è—Ç—å –¥–æ—Ä–æ–≥–æ–π (–ø–æ –≤–µ—Ä—Å–∏–∏ —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª...         25-4  clsorg\n",
       "4124  ‚ö†Ô∏èüá∑üá∫#POLY  –ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è —Å–∞–Ω–∫—Ü–∏–π –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö ...        235-2  clsorg\n",
       "3476  ‚Äã–ü—Ä–∏–≤—ã–∫–∞–π –∂–∏—Ç—å –≤ —Ä—É–±–ª—ë–≤–æ–π –∑–æ–Ω–µüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏...        251-4  clsorg\n",
       "452   \"‚ö†Ô∏èüá∑üá∫#MAGN  –ú–ú–ö –Ω–µ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç buyback –≤ –±–ª–∏–∂–∞–π—à...         90-3  clsorg\n",
       "3159  –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ ¬´–¢–∞—Ç–Ω–µ—Ñ—Ç–∏¬ª —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –≤—ã–ø–ª–∞...        163-4  clsorg\n",
       "5902                           üí•üá∑üá∫#SNGS = –º–∞–∫—Å –∑–∞ 5 –º–µ—Å        160-3  clsorg\n",
       "3563  ‚Äã‚Äã–í–æ–∑—Ä–æ–∂–¥–µ–Ω–∏–µ –ú.–í–∏–¥–µ–æ ‚óè –î–µ–ª–∏–º–æ–±–∏–ª—å —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª ‚óè...   88-3;273-3  clsorg\n",
       "5009  üá∑üá∫#SBER #VTBR #cot  ¬´–°–±–µ—Ä¬ª —Å—Ç–∞–ª —Å–∞–º–æ–π –ø–æ–ø—É–ª—è—Ä–Ω...        150-3  clsorg\n",
       "4967  üá∑üá∫#ROSN #event  –ü—É—Ç–∏–Ω –∏ –°–µ—á–∏–Ω 1 –¥–µ–∫–∞–±—Ä—è –ø–æ–æ–±—â–∞...        112-3  clsorg\n",
       "2063  –ê–ª—Ä–æ—Å–∞ - –∞–ª–º–∞–∑ –∫–æ—Ç–æ—Ä—ã–π –ª–µ–∂–∏—Ç –Ω–∞ –ø–æ–ª—É. –ê–≤—Ç–æ—Ä: i...          4-5  clsorg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [pin]\n",
    "file_path = \"../data/data-hard2.csv\"\n",
    "root_path = \"../data/\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"prefix\"] = \"clsorg\"\n",
    "df = df.rename({\"message\": \"input_text\", \"label\": \"target_text\"}, axis=1)\n",
    "\n",
    "# df[\"input_text\"] = df[\"input_text\"].apply(preprocess_text)\n",
    "df.drop(2764)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "m_name = \"cointegrated/rut5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/src\")\n",
    "\n",
    "from t5.dataset import NERDataModel\n",
    "from t5.model import NERModel\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "data_module = NERDataModel(train_df, test_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel(m_name, lr=0.0006)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints2\",\n",
    "    filename=\"ner\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/lightning_logs\n",
      "/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/.conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/.conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 64.6 M\n",
      "-----------------------------------------------------\n",
      "64.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "64.6 M    Total params\n",
      "258.578   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c8980001254618aeac1370bf791bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/.conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (42) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b8f923beac4310954a66963bf18b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9640a6ed69b5415a89a596ab54b6ea97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 42: 'val_loss' reached 1.72359 (best 1.72359), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a5e335a7874a358381eb2ee678f10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 84: 'val_loss' reached 1.14667 (best 1.14667), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f4be4953024c0c87594e42a5b35ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 126: 'val_loss' reached 0.93560 (best 0.93560), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bfd8128a7b4c4e8fee9cb75fa5824e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 168: 'val_loss' reached 0.91776 (best 0.91776), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v25.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b20331c88643b2922b4919787121ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 210: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.save_pretrained('models/pretrained-rut5-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "m_name = 'models/pretrained-rut5-2'\n",
    "model = NERModel(\n",
    "    m_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NERModel(\n",
       "  (model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(20100, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(20100, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(20100, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:16<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from t5.utils import evaluate_metric, generate_answer_batched\n",
    "\n",
    "with torch.inference_mode():\n",
    "    predictions = generate_answer_batched(\n",
    "        trained_model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data=test_df[:1200],\n",
    "        batch_size=64,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = test_df[:1200].copy()\n",
    "ldf[\"predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "      <th>predictions</th>\n",
       "      <th>tcomp</th>\n",
       "      <th>tsent</th>\n",
       "      <th>pcomp</th>\n",
       "      <th>psent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>‚Äã–Ø–Ω–¥–µ–∫—Å —Ä–∞–∑–±–∏–ª –º–Ω–µ —Å–µ—Ä–¥—Ü–µ –∏ —è –µ–≥–æ –ø—Ä–æ–¥–∞–ª üíî  –Ø ...</td>\n",
       "      <td>236-2</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>236-3</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>\"–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –ü–ê–û \"\"–ù–æ–≤–æ–ª–∏–ø–µ—Ü–∫–∏–π –º–µ—Ç–∞–ª–ª—É—Ä–≥...</td>\n",
       "      <td>116-2</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>116-3</td>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>\"üá∑üá∫#CHMF #–º–Ω–µ–Ω–∏–µ   \"\"–°–µ–≤–µ—Ä—Å—Ç–∞–ª—å\"\" –≤ 2023 –≥–æ–¥—É ...</td>\n",
       "      <td>152-4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>152-4</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>–°–î –°–µ–≤–µ—Ä—Å—Ç–∞–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –∞–∫—Ü–∏–æ–Ω–µ—Ä–∞–º –æ–¥–æ–±—Ä–∏—Ç—å...</td>\n",
       "      <td>152-4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>152-4</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>–ì–ª–∞–≤–Ω–æ–µ –∫ –æ—Ç–∫—Ä—ã—Ç–∏—é —Å—Ä–µ–¥—ã (21.06): #–±—Ä–∏—Ñ–∏–Ω–≥  üìå ...</td>\n",
       "      <td>25-3</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>251-5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>251</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>\"üá∑üá∫#SBER #event  –°–æ–≤—Ñ–µ–¥ –ø—Ä–∏–≥–ª–∞—Å–∏–ª –ì—Ä–µ—Ñ–∞ –≤—ã—Å—Ç—É–ø...</td>\n",
       "      <td>150-3</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>150-4</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>\"‚è∞ 23 —è–Ω–≤–∞—Ä—è - –î–æ–±—Ä–æ–µ —É—Ç—Ä–æ!  üáßüá∑üá¶üá∑ –ë—Ä–∞–∑–∏–ª–∏—è –∏ –ê...</td>\n",
       "      <td>53-4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>53-2</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>‚Äã‚Äãüü¢ –ò–¢–û–ì–ò –î–ù–Ø. –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏ –¥–æ—Ä–æ–∂–∞—é—Ç   ‚ö™Ô∏è ...</td>\n",
       "      <td>160-4;4-2</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>160-4</td>\n",
       "      <td>160</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>‚Äã‚Äã–ì–ª—è–Ω—É–ª –æ—Ç—á—ë—Ç –ø–æ —Å–µ–≥–µ–∂–µ –∑–∞ 22 –≥–æ–¥   –°–º–æ–≥–ª–∏ –¥–æ...</td>\n",
       "      <td>204-3</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>152-4</td>\n",
       "      <td>204</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>\"‚ö†Ô∏èüá∑üá∫#FEES #spo  \"\"–†–æ—Å—Å–µ—Ç–∏\"\" —Å–æ–æ–±—â–∏–ª–∏ –æ –≤–æ–∑–º–æ–∂...</td>\n",
       "      <td>186-2</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>186-2</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text target_text  prefix  \\\n",
       "3518  ‚Äã–Ø–Ω–¥–µ–∫—Å —Ä–∞–∑–±–∏–ª –º–Ω–µ —Å–µ—Ä–¥—Ü–µ –∏ —è –µ–≥–æ –ø—Ä–æ–¥–∞–ª üíî  –Ø ...       236-2  clsorg   \n",
       "319   \"–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –ü–ê–û \"\"–ù–æ–≤–æ–ª–∏–ø–µ—Ü–∫–∏–π –º–µ—Ç–∞–ª–ª—É—Ä–≥...       116-2  clsorg   \n",
       "625   \"üá∑üá∫#CHMF #–º–Ω–µ–Ω–∏–µ   \"\"–°–µ–≤–µ—Ä—Å—Ç–∞–ª—å\"\" –≤ 2023 –≥–æ–¥—É ...       152-4  clsorg   \n",
       "3053  –°–î –°–µ–≤–µ—Ä—Å—Ç–∞–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –∞–∫—Ü–∏–æ–Ω–µ—Ä–∞–º –æ–¥–æ–±—Ä–∏—Ç—å...       152-4  clsorg   \n",
       "2328  –ì–ª–∞–≤–Ω–æ–µ –∫ –æ—Ç–∫—Ä—ã—Ç–∏—é —Å—Ä–µ–¥—ã (21.06): #–±—Ä–∏—Ñ–∏–Ω–≥  üìå ...        25-3  clsorg   \n",
       "...                                                 ...         ...     ...   \n",
       "805   \"üá∑üá∫#SBER #event  –°–æ–≤—Ñ–µ–¥ –ø—Ä–∏–≥–ª–∞—Å–∏–ª –ì—Ä–µ—Ñ–∞ –≤—ã—Å—Ç—É–ø...       150-3  clsorg   \n",
       "410   \"‚è∞ 23 —è–Ω–≤–∞—Ä—è - –î–æ–±—Ä–æ–µ —É—Ç—Ä–æ!  üáßüá∑üá¶üá∑ –ë—Ä–∞–∑–∏–ª–∏—è –∏ –ê...        53-4  clsorg   \n",
       "3821  ‚Äã‚Äãüü¢ –ò–¢–û–ì–ò –î–ù–Ø. –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏ –¥–æ—Ä–æ–∂–∞—é—Ç   ‚ö™Ô∏è ...   160-4;4-2  clsorg   \n",
       "3570  ‚Äã‚Äã–ì–ª—è–Ω—É–ª –æ—Ç—á—ë—Ç –ø–æ —Å–µ–≥–µ–∂–µ –∑–∞ 22 –≥–æ–¥   –°–º–æ–≥–ª–∏ –¥–æ...       204-3  clsorg   \n",
       "438   \"‚ö†Ô∏èüá∑üá∫#FEES #spo  \"\"–†–æ—Å—Å–µ—Ç–∏\"\" —Å–æ–æ–±—â–∏–ª–∏ –æ –≤–æ–∑–º–æ–∂...       186-2  clsorg   \n",
       "\n",
       "     predictions tcomp tsent pcomp psent  \n",
       "3518       236-3   236     2   236     3  \n",
       "319        116-3   116     2   116     3  \n",
       "625        152-4   152     4   152     4  \n",
       "3053       152-4   152     4   152     4  \n",
       "2328       251-5    25     3   251     5  \n",
       "...          ...   ...   ...   ...   ...  \n",
       "805        150-4   150     3   150     4  \n",
       "410         53-2    53     4    53     2  \n",
       "3821       160-4   160     4   160     4  \n",
       "3570       152-4   204     3   152     4  \n",
       "438        186-2   186     2   186     2  \n",
       "\n",
       "[1200 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_predictions(predictions):\n",
    "    predictions = re.sub(r'[^0-9;-]', '', predictions)\n",
    "    pattern = r'\\d+-\\d+'\n",
    "    matches = re.findall(pattern, predictions)\n",
    "    if not matches:\n",
    "        matches = [\"150-3\"]\n",
    "    return ';'.join(matches)\n",
    "\n",
    "ldf['predictions'] = ldf['predictions'].apply(format_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf[[\"tcomp\", \"tsent\"]] = (\n",
    "    ldf[\"target_text\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")\n",
    "ldf[[\"pcomp\", \"psent\"]] = (\n",
    "    ldf[\"predictions\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 66.74816859422192, 'f1': 0.7199633718844386, 'accuracy': 0.615}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metric(\n",
    "    company_predictions=ldf[\"pcomp\"].tolist(),\n",
    "    company_labels=ldf[\"tcomp\"].tolist(),\n",
    "    sentiment_predictions=ldf[\"psent\"].tolist(),\n",
    "    sentiment_labels=ldf[\"tsent\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
