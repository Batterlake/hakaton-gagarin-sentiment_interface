{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>\"‚Äã‚Äã–ü–æ–ª–∏–º–µ—Ç–∞–ª–ª: –ø–æ–∑–≤–æ–ª–∏—Ç –ª–∏ –ø–µ—Ä–µ–µ–∑–¥ –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω...</td>\n",
       "      <td>235-0</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#AKRN  ‚Äú–ê–∫—Ä–æ–Ω‚Äù –±—É–¥–µ—Ç –æ—Å–ø–∞—Ä–∏–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –ü–æ...</td>\n",
       "      <td>24-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>üìâ –õ–∏–¥–µ—Ä—ã –ø–∞–¥–µ–Ω–∏—è –≤ I –∫–≤–∞—Ä—Ç–∞–ª–µ –Ω–∞ —Ä—ã–Ω–∫–µ –†–§  –°–∫–æ...</td>\n",
       "      <td>100-4;236-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>–ê–ª–µ–∫—Å —Ç–æ–∂–µ –ø—Ä–∏—Ö—É–µ–ª –æ—Ç –¥–∏–≤–æ–≤ –≤ MOEX üòÇ</td>\n",
       "      <td>103-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5184</th>\n",
       "      <td>üá∑üá∫#SOFL  15 —Ñ–µ–≤—Ä–∞–ª—è - –°–æ—Ñ—Ç–ª–∞–π–Ω - –î–µ–Ω—å –ò–Ω–≤–µ—Å—Ç–æ—Ä–∞</td>\n",
       "      <td>237-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>‚Äã‚Äãüü¢ –ò–¢–û–ì–ò –î–ù–Ø. –†–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ –∞–∫—Ü–∏–π –ø—Ä–æ–¥–æ–ª–∂–∞...</td>\n",
       "      <td>127-3;36-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>–ú—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ú–æ—Å–ë–∏—Ä–∂—É –∏ —Å—á–∏—Ç–∞–µ–º ...</td>\n",
       "      <td>57-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>–ì–æ–≤–æ—Ä—è—Ç –∫—Å—Ç–∞, —á—Ç–æ —Å–µ–ª–ª–µ—Ä—É –≤ –†–æ—Å–Ω –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –∫–æ—Ä...</td>\n",
       "      <td>112-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>üü¢ –ê—ç—Ä–æ—Ñ–ª–æ—Ç –≤—á–µ—Ä–∞ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –ú–°–§...</td>\n",
       "      <td>32-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>–õ–æ–Ω–≥—É—Å—Ç—ã –≤ –ú–∞–≥–Ω–∏—Ç–µ [MGNT] right now üôà</td>\n",
       "      <td>89-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>\"‚ùóÔ∏èüá∑üá∫#YNDX  –Ø–ù–î–ï–ö–° 30 –ò–Æ–ù–Ø –ü–†–û–í–ï–î–ï–¢ –°–û–ë–†–ê–ù–ò–ï –í...</td>\n",
       "      <td>236-4;7-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>üí•üá∑üá∫#RNFT = +10%</td>\n",
       "      <td>209-3;209-3;209-3;209-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>\"üá∑üá∫#LKOH #–∞—ç \"\"–õ—É–∫–æ–π–ª\"\" —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–¥ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏...</td>\n",
       "      <td>111-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>üí•üá∑üá∫#NVTK #–¥–∏–≤–∏–¥–µ–Ω–¥ –°–î –ù–û–í–ê–¢–≠–ö:  –î–ò–í–ò–î–ï–ù–î–´ 1–ü 2...</td>\n",
       "      <td>115-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>‚Äã‚Äãüü¢ –¢–û–ü —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π —Å—Ä–µ–¥–Ω–µ–π –∏ –º–∞–ª–æ–π –∫–∞–ø–∏—Ç...</td>\n",
       "      <td>129-5;56-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>‚ö™Ô∏è –ì—Ä—É–ø–ø–∞ ¬´–°–∞–º–æ–ª–µ—Ç¬ª –æ–±—ä—è–≤–∏–ª–∞, —á—Ç–æ –µ–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª...</td>\n",
       "      <td>56-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>üü¢ –ù–æ–≤–æ—Å—Ç–∏ –∫ —ç—Ç–æ–º—É —á–∞—Å—É  ‚ö™Ô∏è –ù–µ—Ñ—Ç–µ–≥–∞–∑–æ–≤—ã–µ –¥–æ—Ö–æ–¥—ã...</td>\n",
       "      <td>32-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>üí•üá∑üá∫#POLY #–ª–∏—Å—Ç–∏–Ω–≥  Polymetal –æ–∂–∏–¥–∞–µ—Ç –≤–æ–∑–≤—Ä–∞—â–µ–Ω...</td>\n",
       "      <td>235-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>\"#GCHE –ì—Ä—É–ø–ø–∞ \"\"–ß–µ—Ä–∫–∏–∑–æ–≤–æ\"\" –≤ 2023 –≥. —É–≤–µ–ª–∏—á–∏–ª...</td>\n",
       "      <td>58-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>üÜï –í —Å–æ—Å—Ç–∞–≤ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏ –≤–æ–π–¥–µ—Ç 4 –Ω–æ–≤—ã–µ –±—É–º...</td>\n",
       "      <td>228-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "408   \"‚Äã‚Äã–ü–æ–ª–∏–º–µ—Ç–∞–ª–ª: –ø–æ–∑–≤–æ–ª–∏—Ç –ª–∏ –ø–µ—Ä–µ–µ–∑–¥ –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω...   \n",
       "4182  ‚ö†Ô∏èüá∑üá∫#AKRN  ‚Äú–ê–∫—Ä–æ–Ω‚Äù –±—É–¥–µ—Ç –æ—Å–ø–∞—Ä–∏–≤–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –ü–æ...   \n",
       "6307  üìâ –õ–∏–¥–µ—Ä—ã –ø–∞–¥–µ–Ω–∏—è –≤ I –∫–≤–∞—Ä—Ç–∞–ª–µ –Ω–∞ —Ä—ã–Ω–∫–µ –†–§  –°–∫–æ...   \n",
       "2096               –ê–ª–µ–∫—Å —Ç–æ–∂–µ –ø—Ä–∏—Ö—É–µ–ª –æ—Ç –¥–∏–≤–æ–≤ –≤ MOEX üòÇ   \n",
       "5184    üá∑üá∫#SOFL  15 —Ñ–µ–≤—Ä–∞–ª—è - –°–æ—Ñ—Ç–ª–∞–π–Ω - –î–µ–Ω—å –ò–Ω–≤–µ—Å—Ç–æ—Ä–∞   \n",
       "3984  ‚Äã‚Äãüü¢ –ò–¢–û–ì–ò –î–ù–Ø. –†–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ –∞–∫—Ü–∏–π –ø—Ä–æ–¥–æ–ª–∂–∞...   \n",
       "2673  –ú—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ú–æ—Å–ë–∏—Ä–∂—É –∏ —Å—á–∏—Ç–∞–µ–º ...   \n",
       "2386  –ì–æ–≤–æ—Ä—è—Ç –∫—Å—Ç–∞, —á—Ç–æ —Å–µ–ª–ª–µ—Ä—É –≤ –†–æ—Å–Ω –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ –∫–æ—Ä...   \n",
       "6850  üü¢ –ê—ç—Ä–æ—Ñ–ª–æ—Ç –≤—á–µ—Ä–∞ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –ú–°–§...   \n",
       "2613              –õ–æ–Ω–≥—É—Å—Ç—ã –≤ –ú–∞–≥–Ω–∏—Ç–µ [MGNT] right now üôà   \n",
       "561   \"‚ùóÔ∏èüá∑üá∫#YNDX  –Ø–ù–î–ï–ö–° 30 –ò–Æ–ù–Ø –ü–†–û–í–ï–î–ï–¢ –°–û–ë–†–ê–ù–ò–ï –í...   \n",
       "5983                                    üí•üá∑üá∫#RNFT = +10%   \n",
       "708   \"üá∑üá∫#LKOH #–∞—ç \"\"–õ—É–∫–æ–π–ª\"\" —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–¥ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏...   \n",
       "5950  üí•üá∑üá∫#NVTK #–¥–∏–≤–∏–¥–µ–Ω–¥ –°–î –ù–û–í–ê–¢–≠–ö:  –î–ò–í–ò–î–ï–ù–î–´ 1–ü 2...   \n",
       "4069  ‚Äã‚Äãüü¢ –¢–û–ü —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π —Å—Ä–µ–¥–Ω–µ–π –∏ –º–∞–ª–æ–π –∫–∞–ø–∏—Ç...   \n",
       "4357  ‚ö™Ô∏è –ì—Ä—É–ø–ø–∞ ¬´–°–∞–º–æ–ª–µ—Ç¬ª –æ–±—ä—è–≤–∏–ª–∞, —á—Ç–æ –µ–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª...   \n",
       "6953  üü¢ –ù–æ–≤–æ—Å—Ç–∏ –∫ —ç—Ç–æ–º—É —á–∞—Å—É  ‚ö™Ô∏è –ù–µ—Ñ—Ç–µ–≥–∞–∑–æ–≤—ã–µ –¥–æ—Ö–æ–¥—ã...   \n",
       "5970  üí•üá∑üá∫#POLY #–ª–∏—Å—Ç–∏–Ω–≥  Polymetal –æ–∂–∏–¥–∞–µ—Ç –≤–æ–∑–≤—Ä–∞—â–µ–Ω...   \n",
       "60    \"#GCHE –ì—Ä—É–ø–ø–∞ \"\"–ß–µ—Ä–∫–∏–∑–æ–≤–æ\"\" –≤ 2023 –≥. —É–≤–µ–ª–∏—á–∏–ª...   \n",
       "4632  üÜï –í —Å–æ—Å—Ç–∞–≤ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏ –≤–æ–π–¥–µ—Ç 4 –Ω–æ–≤—ã–µ –±—É–º...   \n",
       "\n",
       "                  target_text  prefix  \n",
       "408                     235-0  clsorg  \n",
       "4182                     24-2  clsorg  \n",
       "6307              100-4;236-4  clsorg  \n",
       "2096                    103-3  clsorg  \n",
       "5184                    237-3  clsorg  \n",
       "3984               127-3;36-4  clsorg  \n",
       "2673                     57-4  clsorg  \n",
       "2386                    112-4  clsorg  \n",
       "6850                     32-3  clsorg  \n",
       "2613                     89-3  clsorg  \n",
       "561                 236-4;7-2  clsorg  \n",
       "5983  209-3;209-3;209-3;209-3  clsorg  \n",
       "708                     111-4  clsorg  \n",
       "5950                    115-4  clsorg  \n",
       "4069               129-5;56-3  clsorg  \n",
       "4357                     56-3  clsorg  \n",
       "6953                     32-2  clsorg  \n",
       "5970                    235-3  clsorg  \n",
       "60                       58-4  clsorg  \n",
       "4632                    228-4  clsorg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Local File System\n",
    "file_path = \"../data/data-hard.csv\"\n",
    "root_path = \"../data/\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"prefix\"] = \"clsorg\"\n",
    "df = df.rename({\"message\": \"input_text\", \"label\": \"target_text\"}, axis=1)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "m_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        source_max_token_length: int = 396,\n",
    "        target_max_token_length: int = 32,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_length = source_max_token_length\n",
    "        self.target_max_token_length = target_max_token_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        source_encoding = tokenizer(\n",
    "            data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            max_length=self.source_max_token_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            # truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_encoding = tokenizer(\n",
    "            data_row[\"target_text\"],\n",
    "            max_length=self.target_max_token_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return dict(\n",
    "            input_text=data_row[\"prefix\"] + \": \" + data_row[\"input_text\"],\n",
    "            target_text=data_row[\"target_text\"],\n",
    "            input_ids=source_encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=source_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataModel(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        batch_size: int = 8,\n",
    "        source_max_token_length=396,\n",
    "        target_max_token_length=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_token_length = source_max_token_length\n",
    "        self.target_max_token_length = target_max_token_length\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = NERDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_length,\n",
    "            self.target_max_token_length,\n",
    "        )\n",
    "\n",
    "        self.test_dataset = NERDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_length,\n",
    "            self.target_max_token_length,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=10\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "data_module = NERDataModel(train_df, test_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            m_name, return_dict=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/worker/workspace/hakaton-gagarin-sentiment_interface/.conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"ner\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/lightning_logs\n",
      "/home/worker/workspace/hakaton-gagarin-sentiment_interface/.conda/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "/home/worker/workspace/hakaton-gagarin-sentiment_interface/.conda/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0f561fdfa9473286287890d4b08806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d45ee28e314db7a10ab888832d46de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6947f27a96cf4268b5a95ef111f27e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 85: 'val_loss' reached 1.66460 (best 1.66460), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v5.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2de248e8cc4eea8fac128b5f24c990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 170: 'val_loss' reached 1.25580 (best 1.25580), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v5.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235e1e73bf62430eb93cd80fb55fef0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 255: 'val_loss' reached 1.15324 (best 1.15324), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v5.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7991ccbe653433ebbd9fc3e7296b6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 340: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7863cb45b9423fabed69e03589608d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 425: 'val_loss' reached 1.14768 (best 1.14768), saving model to '/home/worker/workspace/hakaton-gagarin-sentiment_interface/pybooks/checkpoints/ner-v5.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026e79cf7d7342f19e58fd38479870fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 510: 'val_loss' was not in top 1\n",
      "/home/worker/workspace/hakaton-gagarin-sentiment_interface/.conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = NERModel.load_from_checkpoint(\"checkpoints/ner-v5.ckpt\")\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_answer_batched(data: pd.DataFrame, batch_size: int = 64):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for name, batch in tqdm(data.groupby(np.arange(len(data)) // batch_size)):\n",
    "            source_encoding = tokenizer(\n",
    "                (batch[\"prefix\"] + \": \" + batch[\"input_text\"]).tolist(),\n",
    "                max_length=396,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                add_special_tokens=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "            generated_ids = trained_model.model.generate(\n",
    "                input_ids=source_encoding[\"input_ids\"].cuda(),\n",
    "                attention_mask=source_encoding[\"attention_mask\"].cuda(),\n",
    "                num_beams=3,\n",
    "                max_length=80,\n",
    "                repetition_penalty=1.0,\n",
    "                early_stopping=True,\n",
    "                use_cache=True,\n",
    "            ).cpu()\n",
    "\n",
    "            preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            predictions.append(preds)\n",
    "\n",
    "    return sum(predictions, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fe86c3fc1945e2b0fa9d66159d0a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = generate_answer_batched(test_df, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = test_df.copy()\n",
    "ldf[\"predictions\"] = predictions\n",
    "ldf[[\"tcomp\", \"tsent\"]] = (\n",
    "    ldf[\"target_text\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")\n",
    "ldf[[\"pcomp\", \"psent\"]] = (\n",
    "    ldf[\"predictions\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 57.80824034396828,\n",
       " 'f1': 0.6391920745477017,\n",
       " 'accuracy': 0.5169727323316639}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_score = f1_metric.compute(\n",
    "    predictions=ldf[\"pcomp\"].tolist(),\n",
    "    references=ldf[\"tcomp\"].tolist(),\n",
    "    average=\"weighted\",\n",
    ")\n",
    "acc_score = acc_metric.compute(\n",
    "    predictions=ldf[\"psent\"].tolist(),\n",
    "    references=ldf[\"tsent\"].tolist(),\n",
    ")\n",
    "\n",
    "results = {\"total\": 100 * (f1_score[\"f1\"] + acc_score[\"accuracy\"]) / 2}\n",
    "results.update(f1_score)\n",
    "results.update(acc_score)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5169727323316639}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "final_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
