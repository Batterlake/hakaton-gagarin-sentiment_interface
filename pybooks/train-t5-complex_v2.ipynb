{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def seed_everything(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>üá∑üá∫#TCSG #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ö–û–ù–°–ï–ù–°–£–°: TCS Group –≤–æ I...</td>\n",
       "      <td>225-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>‚è∞ –î–æ–±—Ä–æ–µ —É—Ç—Ä–æ! 16 –º–∞—Ä—Ç–∞  üåç –ù–æ—á–Ω–æ–µ –¥–µ–∂—É—Ä—Å—Ç–≤–æ (–∑...</td>\n",
       "      <td>228-3;251-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>–°–ü–ë –ë–∏—Ä–∂–∞ –Ω–∞—á–Ω–µ—Ç —Ç–æ—Ä–≥–∏ —Ü–µ–Ω–Ω—ã–º–∏ –±—É–º–∞–≥–∞–º–∏ –≤–æ—Å—å–º–∏...</td>\n",
       "      <td>255-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>#SMLT  –û—Ç–∫—É–ø –≤ –∞–∫—Ü–∏—è—Ö –°–∞–º–æ–ª—ë—Ç–∞: –≥—ç–ø –Ω–∞ –æ—Ç–∫—Ä—ã—Ç–∏...</td>\n",
       "      <td>56-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>‚Äã‚Äãüü¢ –ò–¢–û–ì–ò –î–ù–Ø. –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏ –Ω–µ–º–Ω–æ–≥–æ –ø–æ–¥—Ä–æ—Å...</td>\n",
       "      <td>90-2;152-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>‚õîÔ∏è –†–æ—Å—Å–∏—è –∑–∞–ø—Ä–µ—â–∞–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç –±–µ–Ω–∑–∏–Ω–∞. –ö–∞–∫–∏–µ –∫–æ–º...</td>\n",
       "      <td>25-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>üá∑üá∫#SPBE #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ò—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤ –Ω–∞ –°–ü–ë –ë–∏—Ä–∂–µ...</td>\n",
       "      <td>255-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>–ü—Ä–æ—Å—Ç–æ –≤—Å–ø–æ–º–Ω–∏—Ç–µ –∫–∞–∫ –ø—Ä–æ—Å—Ä–∞–ª—Å—è –°–µ–≤–∫–∞ –Ω–∞ –æ–∂–∏–¥–∞–Ω...</td>\n",
       "      <td>90-5</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>üá∑üá∫#–∞–≤–∏–∞ #—Ä–æ—Å—Å–∏—è  –†–æ—Å—Å–∏—è –º–æ–∂–µ—Ç –æ—Ç–∫—Ä—ã—Ç—å –ø—Ä—è–º—ã–µ –∞...</td>\n",
       "      <td>32-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>‚ö°Ô∏è –°–±–µ—Ä (SBER) –æ—Ç—ã–≥—Ä–∞–ª –≤—Å—ë –ø–∞–¥–µ–Ω–∏–µ –Ω–∞ –°–í–û. #—Ö–≤...</td>\n",
       "      <td>150-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>#MSNG #–û—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –ú–æ—Å—ç–Ω–µ—Ä–≥–æ –ø–æ...</td>\n",
       "      <td>215-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>üá∑üá∫#YNDX  –ì—Ä—É–ø–ø–∞ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤, –≤ –∫–æ—Ç–æ—Ä—É—é –º–æ–≥—É—Ç –≤–æ...</td>\n",
       "      <td>236-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#CHMF #—Å–∞–Ω–∫—Ü–∏–∏  –ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Å—É–¥ –æ—Ç–∫–∞–∑–∞–ª—Å—è ...</td>\n",
       "      <td>152-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>üõ¢&gt;87 –¥–æ–ª–ª./–±–∞—Ä—Ä.  —Å—Ç–æ–∏—Ç Brent –≤–ø–µ—Ä–≤—ã–µ —Å —Å–µ—Ä–µ–¥–∏...</td>\n",
       "      <td>111-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>‚ö†Ô∏è#–∞–ª–º–∞–∑—ã #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å #ALRS  De Beers –∑–∞ –ø–æ—Å–ª–µ...</td>\n",
       "      <td>4-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>‚Äã‚Äãüë©‚Äçüëß –ú–∞—Ç—å –∏ –î–∏—Ç—è (MDMG) - –æ–±–∑–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ...</td>\n",
       "      <td>224-2</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>–ü—Ä–æ–¥–∞–∂–∏ —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è —Å –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ–º –∫–ª—é—á–µ–≤–æ–≥–æ —É...</td>\n",
       "      <td>36-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>‚ùóÔ∏èüá∑üá∫#ISKJ #event —Å–µ–≥–æ–¥–Ω—è - 18:00–º—Å–∫ –í–µ–±–∏–Ω–∞—Ä Sb...</td>\n",
       "      <td>150-3</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>#SOFL –°–æ—Ñ—Ç–ª–∞–π–Ω –≤–µ–¥–µ—Ç –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã –æ –ø–æ–∫—É–ø–∫–µ 100%...</td>\n",
       "      <td>237-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>\"üá∑üá∫#IRAO  –°—É–¥ –≤ –õ–∏—Ç–≤–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–∏–ª –≤—ã–≤–µ—Å—Ç–∏ –∏–∑ —Å–∞...</td>\n",
       "      <td>72-4</td>\n",
       "      <td>clsorg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  target_text  prefix\n",
       "5222  üá∑üá∫#TCSG #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ö–û–ù–°–ï–ù–°–£–°: TCS Group –≤–æ I...        225-4  clsorg\n",
       "4135  ‚è∞ –î–æ–±—Ä–æ–µ —É—Ç—Ä–æ! 16 –º–∞—Ä—Ç–∞  üåç –ù–æ—á–Ω–æ–µ –¥–µ–∂—É—Ä—Å—Ç–≤–æ (–∑...  228-3;251-3  clsorg\n",
       "3130  –°–ü–ë –ë–∏—Ä–∂–∞ –Ω–∞—á–Ω–µ—Ç —Ç–æ—Ä–≥–∏ —Ü–µ–Ω–Ω—ã–º–∏ –±—É–º–∞–≥–∞–º–∏ –≤–æ—Å—å–º–∏...        255-4  clsorg\n",
       "1629  #SMLT  –û—Ç–∫—É–ø –≤ –∞–∫—Ü–∏—è—Ö –°–∞–º–æ–ª—ë—Ç–∞: –≥—ç–ø –Ω–∞ –æ—Ç–∫—Ä—ã—Ç–∏...         56-3  clsorg\n",
       "3917  ‚Äã‚Äãüü¢ –ò–¢–û–ì–ò –î–ù–Ø. –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–∫—Ü–∏–∏ –Ω–µ–º–Ω–æ–≥–æ –ø–æ–¥—Ä–æ—Å...   90-2;152-2  clsorg\n",
       "4392  ‚õîÔ∏è –†–æ—Å—Å–∏—è –∑–∞–ø—Ä–µ—â–∞–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç –±–µ–Ω–∑–∏–Ω–∞. –ö–∞–∫–∏–µ –∫–æ–º...         25-2  clsorg\n",
       "5193  üá∑üá∫#SPBE #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ò—Ç–æ–≥–∏ —Ç–æ—Ä–≥–æ–≤ –Ω–∞ –°–ü–ë –ë–∏—Ä–∂–µ...        255-3  clsorg\n",
       "2996  –ü—Ä–æ—Å—Ç–æ –≤—Å–ø–æ–º–Ω–∏—Ç–µ –∫–∞–∫ –ø—Ä–æ—Å—Ä–∞–ª—Å—è –°–µ–≤–∫–∞ –Ω–∞ –æ–∂–∏–¥–∞–Ω...         90-5  clsorg\n",
       "5391  üá∑üá∫#–∞–≤–∏–∞ #—Ä–æ—Å—Å–∏—è  –†–æ—Å—Å–∏—è –º–æ–∂–µ—Ç –æ—Ç–∫—Ä—ã—Ç—å –ø—Ä—è–º—ã–µ –∞...         32-4  clsorg\n",
       "4306  ‚ö°Ô∏è –°–±–µ—Ä (SBER) –æ—Ç—ã–≥—Ä–∞–ª –≤—Å—ë –ø–∞–¥–µ–Ω–∏–µ –Ω–∞ –°–í–û. #—Ö–≤...        150-3  clsorg\n",
       "1492  #MSNG #–û—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –ú–æ—Å—ç–Ω–µ—Ä–≥–æ –ø–æ...        215-4  clsorg\n",
       "5347  üá∑üá∫#YNDX  –ì—Ä—É–ø–ø–∞ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤, –≤ –∫–æ—Ç–æ—Ä—É—é –º–æ–≥—É—Ç –≤–æ...        236-3  clsorg\n",
       "4193  ‚ö†Ô∏èüá∑üá∫#CHMF #—Å–∞–Ω–∫—Ü–∏–∏  –ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Å—É–¥ –æ—Ç–∫–∞–∑–∞–ª—Å—è ...        152-2  clsorg\n",
       "6753  üõ¢>87 –¥–æ–ª–ª./–±–∞—Ä—Ä.  —Å—Ç–æ–∏—Ç Brent –≤–ø–µ—Ä–≤—ã–µ —Å —Å–µ—Ä–µ–¥–∏...        111-4  clsorg\n",
       "4171  ‚ö†Ô∏è#–∞–ª–º–∞–∑—ã #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å #ALRS  De Beers –∑–∞ –ø–æ—Å–ª–µ...          4-2  clsorg\n",
       "3849  ‚Äã‚Äãüë©‚Äçüëß –ú–∞—Ç—å –∏ –î–∏—Ç—è (MDMG) - –æ–±–∑–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ...        224-2  clsorg\n",
       "2986  –ü—Ä–æ–¥–∞–∂–∏ —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è —Å –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ–º –∫–ª—é—á–µ–≤–æ–≥–æ —É...         36-3  clsorg\n",
       "4497  ‚ùóÔ∏èüá∑üá∫#ISKJ #event —Å–µ–≥–æ–¥–Ω—è - 18:00–º—Å–∫ –í–µ–±–∏–Ω–∞—Ä Sb...        150-3  clsorg\n",
       "1656  #SOFL –°–æ—Ñ—Ç–ª–∞–π–Ω –≤–µ–¥–µ—Ç –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã –æ –ø–æ–∫—É–ø–∫–µ 100%...        237-4  clsorg\n",
       "692   \"üá∑üá∫#IRAO  –°—É–¥ –≤ –õ–∏—Ç–≤–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–∏–ª –≤—ã–≤–µ—Å—Ç–∏ –∏–∑ —Å–∞...         72-4  clsorg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [pin]\n",
    "file_path = \"../data/data-hard.csv\"\n",
    "root_path = \"../data/\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"prefix\"] = \"clsorg\"\n",
    "df = df.rename({\"message\": \"input_text\", \"label\": \"target_text\"}, axis=1)\n",
    "\n",
    "# df[\"input_text\"] = df[\"input_text\"].apply(preprocess_text)\n",
    "df.drop(2764)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "m_name = \"cointegrated/rut5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist = [str(num) for num in range(280)]\n",
    "whitelist_ids = [tokenizer.encode(word)[0] for word in whitelist]\n",
    "bad_words_ids=[[id] for id in range(tokenizer.vocab_size) if id not in whitelist_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/src\")\n",
    "\n",
    "from t5.dataset import NERDataModel\n",
    "from t5.model import NERModel\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 4\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "data_module = NERDataModel(train_df, test_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(20100, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(20100, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(20100, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/.conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "model = NERModel(m_name, lr=0.0007)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints2\",\n",
    "    filename=\"ner\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/lightning_logs\n",
      "/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/.conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/.conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 64.6 M\n",
      "-----------------------------------------------------\n",
      "64.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "64.6 M    Total params\n",
      "258.578   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2318d68cba54b5db728e627ceed2ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/.conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47eb40f74d649178f2d1af334c7621d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7390e31176f4fd9bbb822249a25d757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 43: 'val_loss' reached 1.63819 (best 1.63819), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d76911792e421e997839bc4abb63cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 86: 'val_loss' reached 1.05920 (best 1.05920), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ce741856d34576890bbd1fec783a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 129: 'val_loss' reached 0.91543 (best 0.91543), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v21.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dcf115e672475bb3107732fd048e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 172: 'val_loss' reached 0.89289 (best 0.89289), saving model to '/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v21.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# checkpoint_path = \"best_model.pth\"\n",
    "\n",
    "# # Save the entire model state dictionary\n",
    "# torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# trained_model = NERModel(m_name)\n",
    "# trained_model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model = NERModel.load_from_checkpoint(\"/home/worker/workspace/hakatons/hakaton-gagarin-sentiment_interface/pybooks/checkpoints2/ner-v2.ckpt\")\n",
    "# trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('final_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NERModel(\n",
       "  (model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(20100, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(20100, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(20100, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26/26 [00:35<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "from t5.utils import evaluate_metric, generate_answer_batched\n",
    "\n",
    "predictions = generate_answer_batched(\n",
    "    trained_model=model, tokenizer=tokenizer, data=test_df, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = test_df.copy()\n",
    "ldf[\"predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>–¢—Ä–µ–Ω–¥—ã, —Ü–∏—Ñ—Ä—ã, —Ñ–∞–∫—Ç—ã: —Ä—ã–Ω–æ–∫ 14 –º–∞—Ä—Ç–∞   üìâ –í —Å—Ä–µ...</td>\n",
       "      <td>111-4;241-3;160-4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>160-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>üá∑üá∫#SBER #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –°–ë–ï–†–ë–ê–ù–ö –í –Ø–ù–í–ê–†–ï 2023–ì –£...</td>\n",
       "      <td>150-5</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>150-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5062</th>\n",
       "      <td>üá∑üá∫#POSI #–¥–∏–≤–∏–¥–µ–Ω–¥ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ Positive Te...</td>\n",
       "      <td>241-4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>241-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>‚ú¥Ô∏è#MATIC #–∫—Ä–∏–ø—Ç–æ  Polygon —Å—Ç–∞–ª —Å–≤–æ–µ–≥–æ —Ä–æ–¥–∞ –º–∞—è...</td>\n",
       "      <td>235-0</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>235-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>#SBER –°–±–µ—Ä–±–∞–Ω–∫ üî∑ –ê–Ω–æ–º–∞–ª—å–Ω—ã–π –æ–±—ä—ë–º –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ...</td>\n",
       "      <td>150-5</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>150-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>üí•üá∑üá∫#GMKN = –º–∞–∫—Å –∑–∞ 1  –º–µ—Å</td>\n",
       "      <td>53-3</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>53-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è –ü–æ –∏—Ç–æ–≥–∞–º 2023 –≥–æ–¥–∞ –¥–∏–≤–∏–¥–µ–Ω–¥ –ú–ú–ö (MAGN)...</td>\n",
       "      <td>90-4</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>90-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>\"üèÅ –ò—Ç–æ–≥–∏ –¥–Ω—è: 4 –∞–ø—Ä–µ–ª—è  üìà –ü—Ä–∏–≤–∏–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫...</td>\n",
       "      <td>36-4;160-4;187-3;48-3</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>160-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>üü¢ –ù–æ–≤—ã–π –≤—ã–ø—É—Å–∫ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ Top News –æ—Ç...</td>\n",
       "      <td>32-3;227-3;111-3;90-3</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>90-3;111-3;111-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>–ì–ª–∞–≤–Ω–æ–µ –∑–∞ –Ω–µ–¥–µ–ª—é.  –î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π —Å–µ–∑–æ–Ω  –ù–∞—á–∏–Ω–∞–µ...</td>\n",
       "      <td>36-3</td>\n",
       "      <td>clsorg</td>\n",
       "      <td>36-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  \\\n",
       "3337  –¢—Ä–µ–Ω–¥—ã, —Ü–∏—Ñ—Ä—ã, —Ñ–∞–∫—Ç—ã: —Ä—ã–Ω–æ–∫ 14 –º–∞—Ä—Ç–∞   üìâ –í —Å—Ä–µ...   \n",
       "5144  üá∑üá∫#SBER #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –°–ë–ï–†–ë–ê–ù–ö –í –Ø–ù–í–ê–†–ï 2023–ì –£...   \n",
       "5062  üá∑üá∫#POSI #–¥–∏–≤–∏–¥–µ–Ω–¥ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ Positive Te...   \n",
       "4417  ‚ú¥Ô∏è#MATIC #–∫—Ä–∏–ø—Ç–æ  Polygon —Å—Ç–∞–ª —Å–≤–æ–µ–≥–æ —Ä–æ–¥–∞ –º–∞—è...   \n",
       "1615  #SBER –°–±–µ—Ä–±–∞–Ω–∫ üî∑ –ê–Ω–æ–º–∞–ª—å–Ω—ã–π –æ–±—ä—ë–º –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ...   \n",
       "...                                                 ...   \n",
       "5871                          üí•üá∑üá∫#GMKN = –º–∞–∫—Å –∑–∞ 1  –º–µ—Å   \n",
       "4325  ‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è –ü–æ –∏—Ç–æ–≥–∞–º 2023 –≥–æ–¥–∞ –¥–∏–≤–∏–¥–µ–Ω–¥ –ú–ú–ö (MAGN)...   \n",
       "1027  \"üèÅ –ò—Ç–æ–≥–∏ –¥–Ω—è: 4 –∞–ø—Ä–µ–ª—è  üìà –ü—Ä–∏–≤–∏–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫...   \n",
       "7032  üü¢ –ù–æ–≤—ã–π –≤—ã–ø—É—Å–∫ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ Top News –æ—Ç...   \n",
       "2312  –ì–ª–∞–≤–Ω–æ–µ –∑–∞ –Ω–µ–¥–µ–ª—é.  –î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–π —Å–µ–∑–æ–Ω  –ù–∞—á–∏–Ω–∞–µ...   \n",
       "\n",
       "                target_text  prefix       predictions  \n",
       "3337      111-4;241-3;160-4  clsorg             160-5  \n",
       "5144                  150-5  clsorg             150-4  \n",
       "5062                  241-4  clsorg             241-4  \n",
       "4417                  235-0  clsorg             235-0  \n",
       "1615                  150-5  clsorg             150-5  \n",
       "...                     ...     ...               ...  \n",
       "5871                   53-3  clsorg              53-3  \n",
       "4325                   90-4  clsorg              90-4  \n",
       "1027  36-4;160-4;187-3;48-3  clsorg             160-4  \n",
       "7032  32-3;227-3;111-3;90-3  clsorg  90-3;111-3;111-3  \n",
       "2312                   36-3  clsorg              36-3  \n",
       "\n",
       "[1797 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ldf[[\"tcomp\", \"tsent\"]] = (\n",
    "    ldf[\"target_text\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")\n",
    "ldf[[\"pcomp\", \"psent\"]] = (\n",
    "    ldf[\"predictions\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for index, row in ldf.iterrows():\n",
    "    pcomp_digits = re.sub(r'\\D', '', str(row['pcomp']))\n",
    "  \n",
    "    if pcomp_digits == '':\n",
    "        ldf.at[index, 'pcomp'] = '0' \n",
    "    else:\n",
    "        ldf.at[index, 'pcomp'] = pcomp_digits \n",
    "        # try:\n",
    "        #     i = int(row['pcomp'])\n",
    "        # except ValueError:\n",
    "        #     print(row)\n",
    "        #     ldf.at[index, 'pcomp'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 66.44414139494042,\n",
       " 'f1': 0.7178644639589083,\n",
       " 'accuracy': 0.6110183639398998}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [pin]\n",
    "\n",
    "evaluate_metric(\n",
    "    company_predictions=ldf[\"pcomp\"].tolist(),\n",
    "    company_labels=ldf[\"tcomp\"].tolist(),\n",
    "    sentiment_predictions=ldf[\"psent\"].tolist(),\n",
    "    sentiment_labels=ldf[\"tsent\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NERModel(\n",
       "  (model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(20100, 512)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(20100, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(20100, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedActDense(\n",
       "                (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=20100, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_found = ldf[\"target_text\"].values.tolist()\n",
    "\n",
    "results = []\n",
    "\n",
    "for row in entities_found:\n",
    "    for entity in row.split(\";\"):\n",
    "        t = []\n",
    "        tup = entity.split('-')\n",
    "        entity_id, entity_score = tup\n",
    "        t.append((entity_id, entity_score))\n",
    "    results.append(t)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('160', '4')],\n",
       " [('150', '5')],\n",
       " [('241', '4')],\n",
       " [('235', '0')],\n",
       " [('150', '5')],\n",
       " [('241', '4')],\n",
       " [('160', '5')],\n",
       " [('112', '4')],\n",
       " [('56', '4')],\n",
       " [('204', '4')],\n",
       " [('72', '2')],\n",
       " [('90', '4')],\n",
       " [('221', '4')],\n",
       " [('90', '4')],\n",
       " [('56', '3')],\n",
       " [('235', '0')],\n",
       " [('265', '3')],\n",
       " [('36', '4')],\n",
       " [('220', '3')],\n",
       " [('47', '2')],\n",
       " [('48', '3')],\n",
       " [('227', '3')],\n",
       " [('127', '4')],\n",
       " [('111', '4')],\n",
       " [('157', '4')],\n",
       " [('152', '4')],\n",
       " [('56', '3')],\n",
       " [('127', '3')],\n",
       " [('127', '3')],\n",
       " [('224', '3')],\n",
       " [('175', '2')],\n",
       " [('100', '3')],\n",
       " [('103', '4')],\n",
       " [('157', '3')],\n",
       " [('235', '4')],\n",
       " [('254', '4')],\n",
       " [('7', '4')],\n",
       " [('241', '4')],\n",
       " [('56', '3')],\n",
       " [('112', '2')],\n",
       " [('223', '4')],\n",
       " [('150', '4')],\n",
       " [('225', '4')],\n",
       " [('236', '4')],\n",
       " [('111', '5')],\n",
       " [('236', '3')],\n",
       " [('228', '4')],\n",
       " [('33', '3')],\n",
       " [('129', '4')],\n",
       " [('53', '3')],\n",
       " [('236', '3')],\n",
       " [('89', '5')],\n",
       " [('236', '3')],\n",
       " [('7', '2')],\n",
       " [('235', '3')],\n",
       " [('235', '3')],\n",
       " [('235', '0')],\n",
       " [('109', '3')],\n",
       " [('225', '5')],\n",
       " [('160', '5')],\n",
       " [('227', '3')],\n",
       " [('215', '4')],\n",
       " [('157', '3')],\n",
       " [('61', '3')],\n",
       " [('33', '4')],\n",
       " [('103', '4')],\n",
       " [('230', '4')],\n",
       " [('150', '3')],\n",
       " [('157', '4')],\n",
       " [('266', '3')],\n",
       " [('56', '5')],\n",
       " [('53', '4')],\n",
       " [('26', '3')],\n",
       " [('241', '4')],\n",
       " [('255', '5')],\n",
       " [('4', '3')],\n",
       " [('100', '2')],\n",
       " [('53', '3')],\n",
       " [('150', '4')],\n",
       " [('100', '4')],\n",
       " [('11', '3')],\n",
       " [('175', '4')],\n",
       " [('137', '3')],\n",
       " [('89', '4')],\n",
       " [('175', '3')],\n",
       " [('175', '2')],\n",
       " [('231', '4')],\n",
       " [('103', '3')],\n",
       " [('111', '4')],\n",
       " [('111', '4')],\n",
       " [('235', '0')],\n",
       " [('230', '4')],\n",
       " [('22', '3')],\n",
       " [('90', '3')],\n",
       " [('228', '1')],\n",
       " [('157', '4')],\n",
       " [('150', '3')],\n",
       " [('251', '4')],\n",
       " [('116', '0')],\n",
       " [('220', '4')],\n",
       " [('116', '2')],\n",
       " [('112', '4')],\n",
       " [('254', '3')],\n",
       " [('7', '3')],\n",
       " [('99', '3')],\n",
       " [('99', '5')],\n",
       " [('116', '3')],\n",
       " [('225', '4')],\n",
       " [('32', '4')],\n",
       " [('236', '2')],\n",
       " [('24', '4')],\n",
       " [('90', '4')],\n",
       " [('32', '2')],\n",
       " [('26', '4')],\n",
       " [('127', '3')],\n",
       " [('225', '3')],\n",
       " [('127', '3')],\n",
       " [('236', '4')],\n",
       " [('136', '3')],\n",
       " [('230', '4')],\n",
       " [('33', '4')],\n",
       " [('99', '3')],\n",
       " [('11', '2')],\n",
       " [('115', '3')],\n",
       " [('187', '3')],\n",
       " [('163', '4')],\n",
       " [('152', '3')],\n",
       " [('111', '3')],\n",
       " [('150', '3')],\n",
       " [('224', '2')],\n",
       " [('255', '4')],\n",
       " [('187', '4')],\n",
       " [('116', '0')],\n",
       " [('152', '4')],\n",
       " [('90', '3')],\n",
       " [('236', '3')],\n",
       " [('71', '4')],\n",
       " [('11', '4')],\n",
       " [('99', '2')],\n",
       " [('229', '1')],\n",
       " [('265', '3')],\n",
       " [('228', '3')],\n",
       " [('221', '4')],\n",
       " [('235', '3')],\n",
       " [('112', '4')],\n",
       " [('61', '3')],\n",
       " [('231', '3')],\n",
       " [('115', '4')],\n",
       " [('271', '3')],\n",
       " [('230', '4')],\n",
       " [('152', '4')],\n",
       " [('254', '4')],\n",
       " [('157', '4')],\n",
       " [('7', '5')],\n",
       " [('111', '4')],\n",
       " [('254', '5')],\n",
       " [('153', '3')],\n",
       " [('231', '4')],\n",
       " [('241', '3')],\n",
       " [('112', '4')],\n",
       " [('241', '3')],\n",
       " [('111', '5')],\n",
       " [('89', '2')],\n",
       " [('90', '4')],\n",
       " [('57', '3')],\n",
       " [('241', '4')],\n",
       " [('230', '2')],\n",
       " [('7', '2')],\n",
       " [('236', '5')],\n",
       " [('261', '4')],\n",
       " [('127', '4')],\n",
       " [('160', '3')],\n",
       " [('56', '4')],\n",
       " [('273', '3')],\n",
       " [('163', '3')],\n",
       " [('235', '0')],\n",
       " [('72', '3')],\n",
       " [('231', '3')],\n",
       " [('26', '4')],\n",
       " [('218', '3')],\n",
       " [('163', '4')],\n",
       " [('209', '3')],\n",
       " [('224', '2')],\n",
       " [('100', '4')],\n",
       " [('111', '3')],\n",
       " [('223', '4')],\n",
       " [('237', '3')],\n",
       " [('116', '3')],\n",
       " [('230', '3')],\n",
       " [('4', '4')],\n",
       " [('7', '4')],\n",
       " [('186', '3')],\n",
       " [('103', '4')],\n",
       " [('112', '4')],\n",
       " [('204', '3')],\n",
       " [('99', '3')],\n",
       " [('223', '4')],\n",
       " [('36', '5')],\n",
       " [('157', '4')],\n",
       " [('103', '4')],\n",
       " [('236', '4')],\n",
       " [('99', '3')],\n",
       " [('127', '2')],\n",
       " [('230', '3')],\n",
       " [('58', '3')],\n",
       " [('235', '0')],\n",
       " [('230', '4')],\n",
       " [('241', '3')],\n",
       " [('111', '2')],\n",
       " [('100', '4')],\n",
       " [('230', '3')],\n",
       " [('53', '2')],\n",
       " [('58', '4')],\n",
       " [('235', '4')],\n",
       " [('235', '0')],\n",
       " [('270', '4')],\n",
       " [('48', '2')],\n",
       " [('111', '3')],\n",
       " [('230', '3')],\n",
       " [('7', '2')],\n",
       " [('115', '4')],\n",
       " [('89', '3')],\n",
       " [('230', '3')],\n",
       " [('25', '5')],\n",
       " [('153', '4')],\n",
       " [('103', '3')],\n",
       " [('103', '4')],\n",
       " [('254', '4')],\n",
       " [('160', '4')],\n",
       " [('90', '5')],\n",
       " [('127', '3')],\n",
       " [('220', '3')],\n",
       " [('56', '5')],\n",
       " [('88', '3')],\n",
       " [('48', '4')],\n",
       " [('89', '2')],\n",
       " [('111', '3')],\n",
       " [('7', '3')],\n",
       " [('4', '2')],\n",
       " [('227', '5')],\n",
       " [('112', '4')],\n",
       " [('100', '4')],\n",
       " [('11', '2')],\n",
       " [('175', '4')],\n",
       " [('115', '2')],\n",
       " [('88', '4')],\n",
       " [('58', '3')],\n",
       " [('127', '3')],\n",
       " [('103', '4')],\n",
       " [('7', '3')],\n",
       " [('224', '3')],\n",
       " [('160', '4')],\n",
       " [('61', '4')],\n",
       " [('47', '5')],\n",
       " [('204', '4')],\n",
       " [('142', '5')],\n",
       " [('11', '4')],\n",
       " [('74', '3')],\n",
       " [('225', '3')],\n",
       " [('4', '5')],\n",
       " [('7', '3')],\n",
       " [('236', '5')],\n",
       " [('115', '3')],\n",
       " [('160', '5')],\n",
       " [('175', '3')],\n",
       " [('103', '3')],\n",
       " [('150', '3')],\n",
       " [('127', '2')],\n",
       " [('25', '5')],\n",
       " [('241', '4')],\n",
       " [('177', '3')],\n",
       " [('220', '4')],\n",
       " [('90', '3')],\n",
       " [('90', '5')],\n",
       " [('235', '3')],\n",
       " [('228', '4')],\n",
       " [('223', '3')],\n",
       " [('112', '2')],\n",
       " [('103', '3')],\n",
       " [('223', '3')],\n",
       " [('236', '4')],\n",
       " [('33', '4')],\n",
       " [('36', '4')],\n",
       " [('241', '2')],\n",
       " [('116', '2')],\n",
       " [('4', '4')],\n",
       " [('103', '5')],\n",
       " [('225', '4')],\n",
       " [('209', '3')],\n",
       " [('11', '3')],\n",
       " [('53', '3')],\n",
       " [('127', '3')],\n",
       " [('136', '3')],\n",
       " [('157', '4')],\n",
       " [('48', '3')],\n",
       " [('218', '2')],\n",
       " [('89', '4')],\n",
       " [('235', '0')],\n",
       " [('235', '3')],\n",
       " [('150', '3')],\n",
       " [('25', '4')],\n",
       " [('220', '3')],\n",
       " [('103', '4')],\n",
       " [('103', '2')],\n",
       " [('150', '3')],\n",
       " [('225', '3')],\n",
       " [('254', '4')],\n",
       " [('163', '4')],\n",
       " [('218', '4')],\n",
       " [('224', '2')],\n",
       " [('153', '4')],\n",
       " [('273', '4')],\n",
       " [('240', '2')],\n",
       " [('265', '4')],\n",
       " [('111', '5')],\n",
       " [('7', '4')],\n",
       " [('227', '3')],\n",
       " [('4', '3')],\n",
       " [('99', '4')],\n",
       " [('160', '1')],\n",
       " [('48', '2')],\n",
       " [('175', '4')],\n",
       " [('103', '3')],\n",
       " [('223', '4')],\n",
       " [('157', '4')],\n",
       " [('111', '2')],\n",
       " [('25', '3')],\n",
       " [('32', '3')],\n",
       " [('53', '3')],\n",
       " [('157', '3')],\n",
       " [('24', '4')],\n",
       " [('111', '5')],\n",
       " [('111', '3')],\n",
       " [('25', '5')],\n",
       " [('89', '4')],\n",
       " [('48', '4')],\n",
       " [('111', '4')],\n",
       " [('36', '4')],\n",
       " [('163', '4')],\n",
       " [('254', '3')],\n",
       " [('150', '4')],\n",
       " [('163', '3')],\n",
       " [('223', '4')],\n",
       " [('53', '4')],\n",
       " [('187', '3')],\n",
       " [('112', '4')],\n",
       " [('223', '4')],\n",
       " [('184', '3')],\n",
       " [('36', '3')],\n",
       " [('7', '2')],\n",
       " [('152', '4')],\n",
       " [('160', '3')],\n",
       " [('150', '3')],\n",
       " [('235', '0')],\n",
       " [('220', '4')],\n",
       " [('4', '2')],\n",
       " [('103', '3')],\n",
       " [('236', '4')],\n",
       " [('150', '4')],\n",
       " [('175', '4')],\n",
       " [('116', '3')],\n",
       " [('220', '3')],\n",
       " [('163', '4')],\n",
       " [('100', '2')],\n",
       " [('99', '3')],\n",
       " [('150', '3')],\n",
       " [('163', '4')],\n",
       " [('157', '4')],\n",
       " [('241', '4')],\n",
       " [('100', '4')],\n",
       " [('100', '4')],\n",
       " [('111', '4')],\n",
       " [('48', '3')],\n",
       " [('163', '3')],\n",
       " [('11', '4')],\n",
       " [('4', '3')],\n",
       " [('36', '4')],\n",
       " [('47', '4')],\n",
       " [('115', '2')],\n",
       " [('7', '3')],\n",
       " [('127', '2')],\n",
       " [('111', '3')],\n",
       " [('163', '4')],\n",
       " [('100', '4')],\n",
       " [('219', '4')],\n",
       " [('26', '4')],\n",
       " [('4', '2')],\n",
       " [('36', '3')],\n",
       " [('25', '5')],\n",
       " [('251', '4')],\n",
       " [('219', '4')],\n",
       " [('61', '4')],\n",
       " [('142', '4')],\n",
       " [('7', '3')],\n",
       " [('160', '4')],\n",
       " [('32', '4')],\n",
       " [('90', '2')],\n",
       " [('26', '4')],\n",
       " [('53', '4')],\n",
       " [('100', '4')],\n",
       " [('100', '5')],\n",
       " [('224', '4')],\n",
       " [('99', '3')],\n",
       " [('223', '4')],\n",
       " [('7', '4')],\n",
       " [('185', '4')],\n",
       " [('261', '3')],\n",
       " [('254', '1')],\n",
       " [('100', '4')],\n",
       " [('11', '3')],\n",
       " [('231', '4')],\n",
       " [('241', '3')],\n",
       " [('111', '4')],\n",
       " [('115', '4')],\n",
       " [('160', '4')],\n",
       " [('224', '4')],\n",
       " [('100', '4')],\n",
       " [('163', '3')],\n",
       " [('90', '5')],\n",
       " [('53', '3')],\n",
       " [('47', '4')],\n",
       " [('100', '2')],\n",
       " [('204', '4')],\n",
       " [('235', '4')],\n",
       " [('175', '4')],\n",
       " [('204', '3')],\n",
       " [('111', '3')],\n",
       " [('177', '3')],\n",
       " [('235', '3')],\n",
       " [('152', '4')],\n",
       " [('199', '3')],\n",
       " [('241', '4')],\n",
       " [('241', '4')],\n",
       " [('111', '3')],\n",
       " [('58', '4')],\n",
       " [('152', '3')],\n",
       " [('227', '5')],\n",
       " [('127', '2')],\n",
       " [('4', '2')],\n",
       " [('255', '4')],\n",
       " [('11', '3')],\n",
       " [('220', '4')],\n",
       " [('111', '3')],\n",
       " [('36', '3')],\n",
       " [('103', '3')],\n",
       " [('25', '3')],\n",
       " [('115', '4')],\n",
       " [('175', '5')],\n",
       " [('111', '3')],\n",
       " [('227', '3')],\n",
       " [('7', '2')],\n",
       " [('100', '5')],\n",
       " [('157', '4')],\n",
       " [('160', '3')],\n",
       " [('89', '5')],\n",
       " [('11', '3')],\n",
       " [('128', '4')],\n",
       " [('236', '4')],\n",
       " [('204', '3')],\n",
       " [('4', '4')],\n",
       " [('103', '4')],\n",
       " [('127', '3')],\n",
       " [('255', '4')],\n",
       " [('112', '4')],\n",
       " [('228', '3')],\n",
       " [('89', '5')],\n",
       " [('199', '3')],\n",
       " [('115', '4')],\n",
       " [('11', '4')],\n",
       " [('56', '5')],\n",
       " [('111', '4')],\n",
       " [('22', '3')],\n",
       " [('225', '4')],\n",
       " [('53', '3')],\n",
       " [('57', '4')],\n",
       " [('115', '2')],\n",
       " [('163', '3')],\n",
       " [('255', '4')],\n",
       " [('56', '2')],\n",
       " [('218', '3')],\n",
       " [('25', '4')],\n",
       " [('111', '3')],\n",
       " [('235', '2')],\n",
       " [('7', '4')],\n",
       " [('237', '3')],\n",
       " [('150', '3')],\n",
       " [('175', '4')],\n",
       " [('218', '4')],\n",
       " [('72', '4')],\n",
       " [('204', '3')],\n",
       " [('204', '4')],\n",
       " [('235', '0')],\n",
       " [('230', '4')],\n",
       " [('115', '4')],\n",
       " [('163', '3')],\n",
       " [('254', '4')],\n",
       " [('224', '5')],\n",
       " [('227', '4')],\n",
       " [('230', '3')],\n",
       " [('225', '4')],\n",
       " [('103', '4')],\n",
       " [('7', '3')],\n",
       " [('236', '4')],\n",
       " [('150', '3')],\n",
       " [('227', '3')],\n",
       " [('157', '4')],\n",
       " [('187', '4')],\n",
       " [('251', '4')],\n",
       " [('219', '2')],\n",
       " [('118', '3')],\n",
       " [('127', '3')],\n",
       " [('236', '2')],\n",
       " [('7', '4')],\n",
       " [('163', '4')],\n",
       " [('100', '3')],\n",
       " [('219', '4')],\n",
       " [('220', '4')],\n",
       " [('150', '5')],\n",
       " [('99', '2')],\n",
       " [('152', '3')],\n",
       " [('99', '4')],\n",
       " [('7', '2')],\n",
       " [('241', '4')],\n",
       " [('103', '3')],\n",
       " [('152', '2')],\n",
       " [('150', '3')],\n",
       " [('235', '4')],\n",
       " [('204', '4')],\n",
       " [('163', '3')],\n",
       " [('53', '4')],\n",
       " [('175', '4')],\n",
       " [('111', '3')],\n",
       " [('88', '4')],\n",
       " [('129', '5')],\n",
       " [('11', '3')],\n",
       " [('237', '4')],\n",
       " [('56', '3')],\n",
       " [('152', '3')],\n",
       " [('33', '3')],\n",
       " [('150', '4')],\n",
       " [('157', '4')],\n",
       " [('236', '4')],\n",
       " [('225', '3')],\n",
       " [('36', '4')],\n",
       " [('47', '4')],\n",
       " [('99', '2')],\n",
       " [('255', '3')],\n",
       " [('270', '3')],\n",
       " [('48', '4')],\n",
       " [('127', '1')],\n",
       " [('53', '4')],\n",
       " [('127', '5')],\n",
       " [('241', '4')],\n",
       " [('53', '3')],\n",
       " [('255', '4')],\n",
       " [('150', '4')],\n",
       " [('25', '0')],\n",
       " [('72', '3')],\n",
       " [('221', '3')],\n",
       " [('32', '4')],\n",
       " [('99', '3')],\n",
       " [('160', '5')],\n",
       " [('223', '3')],\n",
       " [('36', '3')],\n",
       " [('103', '4')],\n",
       " [('199', '5')],\n",
       " [('112', '4')],\n",
       " [('157', '3')],\n",
       " [('236', '5')],\n",
       " [('160', '4')],\n",
       " [('112', '3')],\n",
       " [('33', '4')],\n",
       " [('100', '4')],\n",
       " [('160', '3')],\n",
       " [('116', '3')],\n",
       " [('160', '4')],\n",
       " [('150', '4')],\n",
       " [('157', '4')],\n",
       " [('255', '4')],\n",
       " [('89', '5')],\n",
       " [('221', '4')],\n",
       " [('53', '2')],\n",
       " [('223', '4')],\n",
       " [('56', '4')],\n",
       " [('33', '4')],\n",
       " [('150', '3')],\n",
       " [('127', '4')],\n",
       " [('127', '4')],\n",
       " [('36', '3')],\n",
       " [('266', '3')],\n",
       " [('254', '4')],\n",
       " [('72', '3')],\n",
       " [('236', '3')],\n",
       " [('204', '3')],\n",
       " [('227', '4')],\n",
       " [('215', '4')],\n",
       " [('116', '2')],\n",
       " [('53', '4')],\n",
       " [('4', '2')],\n",
       " [('230', '4')],\n",
       " [('32', '4')],\n",
       " [('7', '2')],\n",
       " [('185', '4')],\n",
       " [('99', '2')],\n",
       " [('56', '4')],\n",
       " [('236', '3')],\n",
       " [('241', '3')],\n",
       " [('47', '5')],\n",
       " [('112', '5')],\n",
       " [('265', '3')],\n",
       " [('61', '4')],\n",
       " [('89', '4')],\n",
       " [('230', '3')],\n",
       " [('56', '4')],\n",
       " [('150', '3')],\n",
       " [('4', '2')],\n",
       " [('160', '3')],\n",
       " [('227', '3')],\n",
       " [('53', '4')],\n",
       " [('235', '4')],\n",
       " [('150', '3')],\n",
       " [('4', '4')],\n",
       " [('235', '4')],\n",
       " [('235', '4')],\n",
       " [('160', '5')],\n",
       " [('261', '0')],\n",
       " [('258', '4')],\n",
       " [('48', '5')],\n",
       " [('112', '4')],\n",
       " [('175', '4')],\n",
       " [('22', '3')],\n",
       " [('4', '1')],\n",
       " [('33', '3')],\n",
       " [('89', '3')],\n",
       " [('150', '5')],\n",
       " [('127', '3')],\n",
       " [('72', '4')],\n",
       " [('103', '3')],\n",
       " [('36', '3')],\n",
       " [('150', '4')],\n",
       " [('235', '0')],\n",
       " [('4', '3')],\n",
       " [('36', '3')],\n",
       " [('53', '3')],\n",
       " [('142', '4')],\n",
       " [('231', '3')],\n",
       " [('26', '4')],\n",
       " [('157', '3')],\n",
       " [('187', '3')],\n",
       " [('185', '3')],\n",
       " [('112', '4')],\n",
       " [('160', '2')],\n",
       " [('48', '3')],\n",
       " [('254', '4')],\n",
       " [('163', '4')],\n",
       " [('103', '3')],\n",
       " [('150', '3')],\n",
       " [('4', '4')],\n",
       " [('90', '4')],\n",
       " [('100', '2')],\n",
       " [('236', '3')],\n",
       " [('236', '4')],\n",
       " [('160', '4')],\n",
       " [('26', '4')],\n",
       " [('4', '4')],\n",
       " [('160', '4')],\n",
       " [('150', '4')],\n",
       " [('53', '2')],\n",
       " [('150', '3')],\n",
       " [('153', '4')],\n",
       " [('230', '4')],\n",
       " [('111', '4')],\n",
       " [('53', '5')],\n",
       " [('142', '2')],\n",
       " [('115', '5')],\n",
       " [('103', '4')],\n",
       " [('186', '3')],\n",
       " [('111', '3')],\n",
       " [('103', '4')],\n",
       " [('267', '3')],\n",
       " [('127', '3')],\n",
       " [('223', '3')],\n",
       " [('11', '4')],\n",
       " [('273', '3')],\n",
       " [('47', '3')],\n",
       " [('185', '4')],\n",
       " [('58', '4')],\n",
       " [('231', '2')],\n",
       " [('185', '4')],\n",
       " [('61', '3')],\n",
       " [('152', '4')],\n",
       " [('127', '3')],\n",
       " [('223', '3')],\n",
       " [('152', '5')],\n",
       " [('127', '2')],\n",
       " [('186', '3')],\n",
       " [('111', '2')],\n",
       " [('187', '2')],\n",
       " [('7', '3')],\n",
       " [('57', '3')],\n",
       " [('221', '4')],\n",
       " [('103', '4')],\n",
       " [('25', '4')],\n",
       " [('53', '2')],\n",
       " [('224', '2')],\n",
       " [('160', '4')],\n",
       " [('157', '2')],\n",
       " [('56', '4')],\n",
       " [('175', '4')],\n",
       " [('11', '2')],\n",
       " [('258', '3')],\n",
       " [('225', '5')],\n",
       " [('221', '4')],\n",
       " [('175', '4')],\n",
       " [('116', '5')],\n",
       " [('112', '4')],\n",
       " [('7', '2')],\n",
       " [('270', '3')],\n",
       " [('254', '5')],\n",
       " [('115', '3')],\n",
       " [('53', '3')],\n",
       " [('127', '4')],\n",
       " [('251', '3')],\n",
       " [('152', '3')],\n",
       " [('112', '4')],\n",
       " [('7', '2')],\n",
       " [('112', '3')],\n",
       " [('274', '3')],\n",
       " [('230', '3')],\n",
       " [('11', '4')],\n",
       " [('241', '2')],\n",
       " [('100', '4')],\n",
       " [('53', '3')],\n",
       " [('36', '4')],\n",
       " [('227', '3')],\n",
       " [('273', '3')],\n",
       " [('53', '3')],\n",
       " [('7', '4')],\n",
       " [('254', '3')],\n",
       " [('230', '4')],\n",
       " [('100', '4')],\n",
       " [('152', '3')],\n",
       " [('230', '3')],\n",
       " [('160', '4')],\n",
       " [('227', '3')],\n",
       " [('226', '3')],\n",
       " [('48', '3')],\n",
       " [('175', '4')],\n",
       " [('266', '3')],\n",
       " [('115', '3')],\n",
       " [('225', '5')],\n",
       " [('254', '4')],\n",
       " [('4', '3')],\n",
       " [('25', '4')],\n",
       " [('271', '4')],\n",
       " [('111', '3')],\n",
       " [('163', '3')],\n",
       " [('56', '2')],\n",
       " [('261', '0')],\n",
       " [('223', '4')],\n",
       " [('127', '4')],\n",
       " [('236', '4')],\n",
       " [('22', '4')],\n",
       " [('163', '3')],\n",
       " [('254', '3')],\n",
       " [('221', '4')],\n",
       " [('48', '3')],\n",
       " [('228', '4')],\n",
       " [('160', '5')],\n",
       " [('61', '4')],\n",
       " [('32', '3')],\n",
       " [('53', '3')],\n",
       " [('47', '2')],\n",
       " [('265', '4')],\n",
       " [('255', '4')],\n",
       " [('175', '3')],\n",
       " [('236', '4')],\n",
       " [('48', '3')],\n",
       " [('236', '3')],\n",
       " [('48', '3')],\n",
       " [('112', '4')],\n",
       " [('237', '3')],\n",
       " [('56', '4')],\n",
       " [('4', '2')],\n",
       " [('48', '4')],\n",
       " [('89', '3')],\n",
       " [('58', '3')],\n",
       " [('142', '4')],\n",
       " [('7', '4')],\n",
       " [('235', '4')],\n",
       " [('204', '3')],\n",
       " [('157', '3')],\n",
       " [('235', '3')],\n",
       " [('25', '4')],\n",
       " [('25', '4')],\n",
       " [('209', '2')],\n",
       " [('118', '2')],\n",
       " [('100', '4')],\n",
       " [('150', '3')],\n",
       " [('115', '2')],\n",
       " [('235', '0')],\n",
       " [('163', '5')],\n",
       " [('187', '3')],\n",
       " [('150', '3')],\n",
       " [('7', '3')],\n",
       " [('100', '3')],\n",
       " [('224', '4')],\n",
       " [('186', '4')],\n",
       " [('7', '3')],\n",
       " [('103', '4')],\n",
       " [('99', '4')],\n",
       " [('228', '3')],\n",
       " [('187', '2')],\n",
       " [('142', '3')],\n",
       " [('163', '3')],\n",
       " [('271', '3')],\n",
       " [('99', '4')],\n",
       " [('36', '5')],\n",
       " [('7', '3')],\n",
       " [('56', '2')],\n",
       " [('175', '4')],\n",
       " [('142', '2')],\n",
       " [('142', '4')],\n",
       " [('103', '3')],\n",
       " [('235', '4')],\n",
       " [('7', '3')],\n",
       " [('52', '3')],\n",
       " [('254', '4')],\n",
       " [('150', '4')],\n",
       " [('187', '4')],\n",
       " [('47', '4')],\n",
       " [('231', '4')],\n",
       " [('56', '4')],\n",
       " [('185', '4')],\n",
       " [('220', '4')],\n",
       " [('219', '3')],\n",
       " [('255', '2')],\n",
       " [('223', '3')],\n",
       " [('235', '4')],\n",
       " [('153', '3')],\n",
       " [('144', '3')],\n",
       " [('254', '4')],\n",
       " [('53', '3')],\n",
       " [('235', '3')],\n",
       " [('235', '2')],\n",
       " [('224', '3')],\n",
       " [('48', '3')],\n",
       " [('163', '3')],\n",
       " [('4', '3')],\n",
       " [('236', '4')],\n",
       " [('90', '4')],\n",
       " [('157', '3')],\n",
       " [('26', '4')],\n",
       " [('32', '3')],\n",
       " [('199', '3')],\n",
       " [('204', '3')],\n",
       " [('111', '4')],\n",
       " [('112', '3')],\n",
       " [('7', '4')],\n",
       " [('90', '2')],\n",
       " [('47', '5')],\n",
       " [('220', '3')],\n",
       " [('36', '4')],\n",
       " [('72', '3')],\n",
       " [('89', '2')],\n",
       " [('136', '3')],\n",
       " [('157', '4')],\n",
       " [('204', '3')],\n",
       " [('103', '0')],\n",
       " [('223', '4')],\n",
       " [('236', '4')],\n",
       " [('142', '4')],\n",
       " [('111', '3')],\n",
       " [('100', '2')],\n",
       " [('258', '4')],\n",
       " [('235', '4')],\n",
       " [('7', '4')],\n",
       " [('103', '4')],\n",
       " [('225', '4')],\n",
       " [('163', '4')],\n",
       " [('53', '2')],\n",
       " [('235', '0')],\n",
       " [('11', '3')],\n",
       " [('204', '3')],\n",
       " [('225', '3')],\n",
       " [('228', '4')],\n",
       " [('157', '5')],\n",
       " [('150', '4')],\n",
       " [('241', '4')],\n",
       " [('112', '4')],\n",
       " [('90', '4')],\n",
       " [('36', '3')],\n",
       " [('25', '5')],\n",
       " [('160', '3')],\n",
       " [('33', '2')],\n",
       " [('204', '3')],\n",
       " [('157', '4')],\n",
       " [('99', '5')],\n",
       " [('100', '4')],\n",
       " [('100', '4')],\n",
       " [('127', '3')],\n",
       " [('236', '4')],\n",
       " [('32', '3')],\n",
       " [('4', '2')],\n",
       " [('223', '3')],\n",
       " [('26', '3')],\n",
       " [('273', '3')],\n",
       " [('231', '3')],\n",
       " [('142', '4')],\n",
       " [('235', '0')],\n",
       " [('236', '4')],\n",
       " [('157', '4')],\n",
       " [('220', '3')],\n",
       " [('235', '0')],\n",
       " [('47', '4')],\n",
       " [('230', '4')],\n",
       " [('236', '4')],\n",
       " [('218', '3')],\n",
       " [('127', '3')],\n",
       " [('90', '3')],\n",
       " [('72', '4')],\n",
       " [('185', '3')],\n",
       " [('109', '3')],\n",
       " [('160', '3')],\n",
       " [('103', '4')],\n",
       " [('255', '4')],\n",
       " [('236', '2')],\n",
       " [('116', '2')],\n",
       " [('163', '4')],\n",
       " [('223', '3')],\n",
       " [('231', '3')],\n",
       " [('241', '4')],\n",
       " [('163', '4')],\n",
       " [('150', '4')],\n",
       " [('187', '3')],\n",
       " [('7', '4')],\n",
       " [('266', '4')],\n",
       " [('4', '4')],\n",
       " [('129', '1')],\n",
       " [('230', '3')],\n",
       " [('111', '4')],\n",
       " [('25', '4')],\n",
       " [('230', '3')],\n",
       " [('228', '2')],\n",
       " [('48', '3')],\n",
       " [('187', '2')],\n",
       " [('36', '4')],\n",
       " [('103', '3')],\n",
       " [('115', '3')],\n",
       " [('33', '3')],\n",
       " [('225', '3')],\n",
       " [('236', '5')],\n",
       " [('227', '3')],\n",
       " [('228', '2')],\n",
       " [('220', '4')],\n",
       " [('255', '3')],\n",
       " [('100', '4')],\n",
       " [('111', '4')],\n",
       " [('36', '3')],\n",
       " [('115', '4')],\n",
       " [('103', '4')],\n",
       " [('235', '0')],\n",
       " [('26', '5')],\n",
       " [('103', '3')],\n",
       " [('32', '4')],\n",
       " [('225', '4')],\n",
       " [('32', '2')],\n",
       " [('265', '3')],\n",
       " [('236', '3')],\n",
       " [('115', '2')],\n",
       " [('111', '2')],\n",
       " [('175', '4')],\n",
       " [('116', '4')],\n",
       " [('100', '4')],\n",
       " [('231', '5')],\n",
       " [('100', '3')],\n",
       " [('7', '2')],\n",
       " [('32', '3')],\n",
       " [('236', '5')],\n",
       " [('89', '4')],\n",
       " [('11', '2')],\n",
       " [('186', '3')],\n",
       " [('36', '4')],\n",
       " [('235', '0')],\n",
       " [('255', '4')],\n",
       " [('100', '3')],\n",
       " [('111', '3')],\n",
       " [('227', '4')],\n",
       " [('160', '3')],\n",
       " [('261', '0')],\n",
       " [('223', '4')],\n",
       " [('7', '3')],\n",
       " [('157', '3')],\n",
       " [('111', '4')],\n",
       " [('235', '3')],\n",
       " [('7', '3')],\n",
       " [('186', '2')],\n",
       " [('227', '5')],\n",
       " [('115', '4')],\n",
       " [('56', '4')],\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.save(model, 'final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
