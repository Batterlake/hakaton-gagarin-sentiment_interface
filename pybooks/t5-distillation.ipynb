{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "\n",
    "class DistillNERModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, teacher: T5ForConditionalGeneration, student: T5ForConditionalGeneration\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.teacher_model = teacher.requires_grad_(False)\n",
    "        self.student_model = student\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # teacher_output = self.teacher_model(\n",
    "        #     input_ids=input_ids,\n",
    "        #     attention_mask=attention_mask,\n",
    "        #     labels=labels,\n",
    "        #     output_hidden_states=True,\n",
    "        # )\n",
    "        student_output = self.student_model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "\n",
    "        return student_output.loss, student_output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/data-hard.csv\"\n",
    "root_path = \"../data/\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"prefix\"] = \"clsorg\"\n",
    "df = df.rename({\"message\": \"input_text\", \"label\": \"target_text\"}, axis=1)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def get_student_t5_model(model):\n",
    "    new_model = deepcopy(model)\n",
    "    encoder = new_model.encoder\n",
    "    decoder = new_model.decoder\n",
    "    print(len(encoder.block))\n",
    "    for i in [3, 1]:\n",
    "        encoder.block.pop(i)\n",
    "\n",
    "    print(len(decoder.block))\n",
    "    for i in [3, 1]:\n",
    "        decoder.block.pop(i)\n",
    "\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(m_name)\n",
    "teacher_model = T5ForConditionalGeneration.from_pretrained(\"./pretrained/\")\n",
    "student_model = get_student_t5_model(teacher_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3204871780546399"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [pin]\n",
    "count_parameters(teacher_model) / count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.t5.dataset import NERDataModel\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)\n",
    "data_module = NERDataModel(\n",
    "    train_df, test_df, tokenizer, batch_size=BATCH_SIZE, source_max_token_length=396\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data_module.train_dataloader()\n",
    "encoded_batch = next(iter(loader))\n",
    "encoded_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_out = teacher_model(\n",
    "    input_ids=encoded_batch[\"input_ids\"],\n",
    "    attention_mask=encoded_batch[\"attention_mask\"],\n",
    "    labels=encoded_batch[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45821440"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [pin]\n",
    "count_parameters(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     teacher_out = teacher_model(\n",
    "#         input_ids=encoded_batch[\"input_ids\"],\n",
    "#         attention_mask=encoded_batch[\"attention_mask\"],\n",
    "#         labels=encoded_batch[\"labels\"],\n",
    "#         output_hidden_states=True,\n",
    "#     )\n",
    "#     student_out = student_model(\n",
    "#         input_ids=encoded_batch[\"input_ids\"].cuda(),\n",
    "#         attention_mask=encoded_batch[\"attention_mask\"].cuda(),\n",
    "#         labels=encoded_batch[\"labels\"].cuda(),\n",
    "#         output_hidden_states=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl_loss = torch.nn.KLDivLoss()\n",
    "# def distillation_loss(teacher_output, student_output):\n",
    "#     loss = 0\n",
    "#     for i, tdhs in enumerate(teacher_output)\n",
    "#     decoder_loss = teacher_output['decoder_hidden_states'][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0,2,4,5,6\n",
    "# teacher_out[\"encoder_hidden_states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.cuda()\n",
    "teacher_model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.t5.utils import evaluate_metric, generate_answer_batched\n",
    "\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "    predictions = generate_answer_batched(\n",
    "        trained_model=student_model,\n",
    "        tokenizer=tokenizer,\n",
    "        data=test_df[:1200],\n",
    "        batch_size=64,\n",
    "        max_length=396,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.t5.utils import generate_answer_batched\n",
    "\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast():\n",
    "    predictions = generate_answer_batched(\n",
    "        trained_model=teacher_model,\n",
    "        tokenizer=tokenizer,\n",
    "        data=test_df[:1200],\n",
    "        batch_size=64,\n",
    "        max_length=396,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = test_df.copy()[:1200]\n",
    "ldf[\"predictions\"] = predictions\n",
    "ldf[[\"tcomp\", \"tsent\"]] = (\n",
    "    ldf[\"target_text\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")\n",
    "ldf[[\"pcomp\", \"psent\"]] = (\n",
    "    ldf[\"predictions\"].str.split(\";\", expand=True)[0].str.split(\"-\", expand=True)\n",
    ")\n",
    "\n",
    "ldf.drop(\n",
    "    index=ldf[ldf[\"pcomp\"].str.findall(r\"[^\\d]\").str.len() > 0].index, inplace=True\n",
    ")\n",
    "ldf[\"psent\"] = ldf[\"psent\"].fillna(1).replace(\"0\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 32.873398668342645,\n",
       " 'f1': 0.25963644709495964,\n",
       " 'accuracy': 0.3978315262718932}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [pin]\n",
    "\n",
    "evaluate_metric(\n",
    "    company_predictions=ldf[\"pcomp\"].tolist(),\n",
    "    company_labels=ldf[\"tcomp\"].tolist(),\n",
    "    sentiment_predictions=ldf[\"psent\"].tolist(),\n",
    "    sentiment_labels=ldf[\"tsent\"].tolist(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
